{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xanadu Rewards Application - Deployment Guide\n",
    "\n",
    "<div style=\"background-color: #f8f9fa; border: 1px solid #e9ecef; border-radius: 8px; padding: 10px; margin: 10px;\">\n",
    "<strong>üìã Workshop Contents</strong>\n",
    "<ul style=\"line-height: 1.2;\">\n",
    "<li><a href=\"#Prerequisites\">Prerequisites</a></li>\n",
    "<li><a href=\"#Step-1-Repository-Setup\">Step 1: Repository Setup (Choose Your Deployment Option)</a></li>\n",
    "<li><a href=\"#Step-2-Set-Environment-Variables\">Step 2: Set Environment Variables</a></li>\n",
    "<li><a href=\"#Step-3-Verify-Project-Structure\">Step 3: Verify Project Structure</a></li>\n",
    "<li><a href=\"#Step-4-Download-Product-Images-and-SQL-Files\">Step 4: Download Product Images and SQL Files</a></li>\n",
    "<li><a href=\"#Step-5-Prepare-Lambda-Functions-and-Layer\">Step 5: Prepare Lambda Functions and Layer</a></li>\n",
    "<li><a href=\"#Step-6-Create-S3-Bucket\">Step 6: Create S3 Bucket</a></li>\n",
    "<li><a href=\"#Step-7-Upload-Lambda-Code-and-Layer-to-S3\">Step 7: Upload Lambda Code and Layer to S3</a></li>\n",
    "<li><a href=\"#Step-8-Deploy-CloudFormation-Stack\">Step 8: Deploy CloudFormation Stack</a></li>\n",
    "<li><a href=\"#Step-9-Get-CloudFormation-Outputs\">Step 9: Get CloudFormation Outputs</a></li>\n",
    "<li><a href=\"#Step-10-Update-Environment-Variables\">Step 10: Update Environment Variables</a></li>\n",
    "<li><a href=\"#Step-11-Build-the-Frontend\">Step 11: Build the Frontend</a></li>\n",
    "<li><a href=\"#Step-12-Update-Lambda-Function\">Step 12: Update Lambda Function</a></li>\n",
    "<li><a href=\"#Step-13-Test-the-API-Endpoints\">Step 13: Test the API Endpoints</a></li>\n",
    "<li><a href=\"#Step-14-Create-Test-User\">Step 14: Create Test User</a></li>\n",
    "<li><a href=\"#Step-15-Access-the-Application\">Step 15: Access the Application</a></li>\n",
    "<li><a href=\"#Step-16-Monitoring-and-Troubleshooting\">Step 16: Monitoring and Troubleshooting</a></li>\n",
    "<li><a href=\"#Step-17-Cleanup\">Step 17: Cleanup</a></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "This notebook provides step-by-step instructions for deploying the Xanadu Rewards Application on AWS. The application consists of a React frontend and a serverless backend using AWS services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before starting the deployment, ensure you have the following prerequisites:\n",
    "\n",
    "### Required Software\n",
    "1. **AWS CLI** installed and configured with appropriate permissions\n",
    "2. **Node.js and npm** installed (version 18 or higher recommended)\n",
    "3. **Git** installed\n",
    "4. **Python 3** with Jupyter Notebook support\n",
    "\n",
    "### AWS Account Requirements\n",
    "\n",
    "**AWS Account** with sufficient permissions to create:\n",
    "   - VPC and networking resources\n",
    "   - Aurora PostgreSQL Serverless v2\n",
    "   - Lambda functions and layers\n",
    "   - API Gateway\n",
    "   - Cognito User Pool\n",
    "   - Amplify hosting\n",
    "   - S3 buckets\n",
    "   - CloudFormation stacks\n",
    "\n",
    "**Jupyter Notebook**: You can launch a [free tier Amazon SageMaker Jupyter Notebook](../../1_Getting_Started_with_AWS/1.4_Setting_up_Your_Cookbook_Environment/README.MD)\n",
    "\n",
    "### GitHub Integration\n",
    "1. **GitHub account** with a repository for the application\n",
    "2. **GitHub OAuth token** with repo access (for Amplify deployment)\n",
    "   - Go to GitHub Settings > Developer settings > Personal access tokens\n",
    "   - Generate a token with 'repo' scope\n",
    "\n",
    "### Cost Considerations\n",
    "‚ö†Ô∏è **Important**: This deployment creates billable AWS resources. **Estimated monthly cost: $15-75** depending on usage patterns:\n",
    "\n",
    "**Major cost components:**\n",
    "- Aurora Serverless v2: $8-40/month (0-4 ACUs, varies by usage)\n",
    "- NAT Gateway: $32/month (always-on)\n",
    "- RDS Proxy: $10/month (always-on)\n",
    "- Lambda, API Gateway, S3, Amplify: $2-8/month (usage-based)\n",
    "- KMS keys: $4/month (4 keys)\n",
    "\n",
    "**Cost optimization tips:**\n",
    "- Aurora scales to 0 ACUs when idle (saves ~$8/month during inactive periods)\n",
    "- Consider removing NAT Gateway for development environments\n",
    "- Use [AWS Pricing Calculator](https://calculator.aws) for detailed estimates\n",
    "\n",
    "**Remember to run the cleanup step when done testing to avoid ongoing charges.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Repository Setup\n",
    "\n",
    "Choose one of the following options based on your preferred setup:\n",
    "\n",
    "### üìã Repository Setup Options:\n",
    "\n",
    "#### Option A: Using the full DB Cookbook repository\n",
    "- Fork/clone the entire db-cookbook repository\n",
    "- Amplify will build from the subfolder\n",
    "- Repository: `https://github.com/your-username/db-cookbook`\n",
    "\n",
    "#### Option B: Create a separate repository for just the rewards app\n",
    "- Copy the rewards-app-example folder to a new repository\n",
    "- Amplify will build from the repository root\n",
    "- Repository: `https://github.com/your-username/rewards-app-example`\n",
    "\n",
    "### üìù Instructions:\n",
    "\n",
    "#### Option A - Using DB Cookbook Repository:\n",
    "1. Fork the db-cookbook repository on GitHub\n",
    "2. Clone your fork: `git clone https://github.com/YOUR-USERNAME/db-cookbook.git`\n",
    "3. Navigate to: `cd db-cookbook/3_Building_Your_First_Serverless_Web_App_with_Aurora/rewards-app-example`\n",
    "4. Set `GITHUB_REPO = 'db-cookbook'` in Step 2\n",
    "\n",
    "#### Option B - Separate Repository:\n",
    "1. Create a new repository on GitHub: `rewards-app-example`\n",
    "2. Copy the contents of rewards-app-example folder to your new repo\n",
    "3. Push the code to your repository\n",
    "4. Set `GITHUB_REPO = 'rewards-app-example'` in Step 2\n",
    "5. Update CloudFormation template (remove subfolder paths from BuildSpec)\n",
    "\n",
    "**Run the code cell below to select your option:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository Setup - Choose your deployment scenario\n",
    "\n",
    "# Get user choice\n",
    "choice = input(\"Which option are you using? (A/B): \").upper()\n",
    "\n",
    "if choice == 'A':\n",
    "    REPO_TYPE = 'cookbook'\n",
    "    DEFAULT_REPO_NAME = 'db-cookbook'\n",
    "    print(\"‚úì Using Option A: DB Cookbook repository\")\n",
    "elif choice == 'B':\n",
    "    REPO_TYPE = 'separate'\n",
    "    DEFAULT_REPO_NAME = 'rewards-app-example'\n",
    "    print(\"‚úì Using Option B: Separate repository\")\n",
    "    print(\"‚ö†Ô∏è  Remember to update the CloudFormation template for separate repo!\")\n",
    "else:\n",
    "    REPO_TYPE = 'cookbook'\n",
    "    DEFAULT_REPO_NAME = 'db-cookbook'\n",
    "    print(\"‚ö†Ô∏è  Invalid choice, defaulting to Option A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Environment Variables\n",
    "\n",
    "This step configures essential environment variables for the deployment including AWS region, stack name, S3 bucket, and GitHub repository details. The script automatically detects your current AWS region and sets up variables for CloudFormation deployment. You'll see the configured values displayed for verification before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate prerequisites and set configuration variables\n",
    "import os\n",
    "import uuid\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Check required tools\n",
    "def check_tool(tool_name, command):\n",
    "    try:\n",
    "        result = subprocess.run(command, capture_output=True, text=True, shell=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úì {tool_name} is available\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚úó {tool_name} is not available or not configured\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {tool_name} check failed: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"Checking prerequisites...\")\n",
    "tools_ok = True\n",
    "tools_ok &= check_tool(\"AWS CLI\", \"aws --version\")\n",
    "tools_ok &= check_tool(\"Node.js\", \"node --version\")\n",
    "tools_ok &= check_tool(\"npm\", \"npm --version\")\n",
    "tools_ok &= check_tool(\"zip\", \"zip --version\")\n",
    "\n",
    "if not tools_ok:\n",
    "    print(\"‚ö†Ô∏è Please install missing tools before proceeding.\")\n",
    "else:\n",
    "    print(\"‚úì All prerequisites are available!\")\n",
    "\n",
    "# Get current AWS region or use default\n",
    "REGION = !aws configure get region\n",
    "REGION = REGION[0] if REGION else \"us-west-2\"\n",
    "\n",
    "# Generate unique bucket name to avoid conflicts\n",
    "UNIQUE_ID = str(uuid.uuid4())[:8]\n",
    "\n",
    "# Set other variables - REPLACE THESE WITH YOUR VALUES\n",
    "STACK_NAME = \"rewards-app-example\"\n",
    "ENVIRONMENT = \"dev\"\n",
    "BUCKET_NAME = f\"xanadu-rewards-app-{UNIQUE_ID}\"  # Unique S3 bucket name\n",
    "GITHUB_OWNER = \"your-github-username\"  # ‚ö†Ô∏è REPLACE with your GitHub username\n",
    "\n",
    "# Set repository name based on chosen option\n",
    "if 'REPO_TYPE' in locals():\n",
    "    GITHUB_REPO = DEFAULT_REPO_NAME\n",
    "else:\n",
    "    GITHUB_REPO = \"db-cookbook\"  # Default to cookbook repo\n",
    "\n",
    "GITHUB_TOKEN = \"your-github-oauth-token\"  # ‚ö†Ô∏è REPLACE with your GitHub OAuth token\n",
    "\n",
    "# Validate configuration\n",
    "if GITHUB_OWNER == \"your-github-username\" or GITHUB_TOKEN == \"your-github-oauth-token\":\n",
    "    print(\"‚ö†Ô∏è WARNING: Please update GITHUB_OWNER and GITHUB_TOKEN with your actual values!\")\n",
    "\n",
    "if 'REPO_TYPE' in locals() and REPO_TYPE == 'separate':\n",
    "    print(\"üìù Note: Using separate repository - ensure CloudFormation template is updated!\")\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"Using region: {REGION}\")\n",
    "print(f\"Stack name: {STACK_NAME}\")\n",
    "print(f\"S3 bucket: {BUCKET_NAME}\")\n",
    "print(f\"Unique ID: {UNIQUE_ID}\")\n",
    "print(f\"GitHub Owner: {GITHUB_OWNER}\")\n",
    "print(f\"GitHub Repo: {GITHUB_REPO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Project Structure\n",
    "\n",
    "This step verifies that all necessary files are present in the current directory. The project includes all frontend React components, backend Lambda functions, and CloudFormation templates needed for deployment. You'll see a listing of the project structure to confirm all files are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify project structure\n",
    "import os\n",
    "\n",
    "# Check if we're in the correct directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "\n",
    "# List key directories and files\n",
    "required_items = ['cfn', 'lambda', 'src', 'package.json', 'scripts']\n",
    "missing_items = []\n",
    "\n",
    "for item in required_items:\n",
    "    if os.path.exists(item):\n",
    "        print(f\"‚úì {item} found\")\n",
    "    else:\n",
    "        print(f\"‚úó {item} missing\")\n",
    "        missing_items.append(item)\n",
    "\n",
    "# Check for images and SQL directories\n",
    "if not os.path.exists('images'):\n",
    "    print(\"‚úì Images directory not present (will be downloaded in Step 4)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Images directory already exists - will be used for deployment\")\n",
    "\n",
    "if not os.path.exists('lambda/sql'):\n",
    "    print(\"‚úì SQL directory not present (will be downloaded in Step 4)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SQL directory already exists - will be used for deployment\")\n",
    "\n",
    "if missing_items:\n",
    "    print(f\"Warning: Missing items: {missing_items}\")\n",
    "else:\n",
    "    print(\"‚úì All required project files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Download Product Images and SQL Files\n",
    "\n",
    "This step downloads product images and SQL files from [AWS Workshop Studio](https://catalog.workshops.aws/) using the provided URLs. These files are used for the application's product catalog and database initialization, and will be uploaded to S3 in a later step.\n",
    "\n",
    "- Images URL: `https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/bbc211ed-aba2-4a6a-a2bf-227fffd3ce99/xanadu-app/images.zip`\n",
    "- SQL URL: `https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/bbc211ed-aba2-4a6a-a2bf-227fffd3ce99/xanadu-app/sql.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 1. Download product images if they don't already exist\n",
    "IMAGES_URL=\"https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/bbc211ed-aba2-4a6a-a2bf-227fffd3ce99/xanadu-app/images.zip\"\n",
    "\n",
    "if [ -d \"images\" ] && [ \"$(ls -A images 2>/dev/null)\" ]; then\n",
    "    echo \"‚úì Using existing product images in images/ ($(ls images | wc -l) files)\"\n",
    "else\n",
    "    echo \"Downloading product images from provided URL...\"\n",
    "    mkdir -p images\n",
    "    wget -q $IMAGES_URL -O /tmp/images.zip\n",
    "    unzip -q /tmp/images.zip -d /tmp\n",
    "    cp -r /tmp/images/* images/\n",
    "    rm -rf /tmp/images.zip /tmp/images\n",
    "    echo \"‚úì Downloaded $(ls images | wc -l) product images\"\n",
    "fi\n",
    "\n",
    "# 2. Download SQL files if they don't already exist\n",
    "SQL_URL=\"https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/bbc211ed-aba2-4a6a-a2bf-227fffd3ce99/xanadu-app/sql.zip\"\n",
    "\n",
    "if [ -d \"lambda/sql\" ] && [ \"$(ls -A lambda/sql 2>/dev/null)\" ]; then\n",
    "    echo \"‚úì Using existing SQL files in lambda/sql/ ($(ls lambda/sql | wc -l) files)\"\n",
    "    ls -la lambda/sql/\n",
    "else\n",
    "    echo \"Downloading SQL files from provided URL...\"\n",
    "    mkdir -p lambda/sql\n",
    "    wget -q $SQL_URL -O /tmp/sql.zip\n",
    "    unzip -q /tmp/sql.zip -d /tmp\n",
    "    cp -r /tmp/sql/* lambda/sql/\n",
    "    rm -rf /tmp/sql.zip /tmp/sql\n",
    "    echo \"‚úì Copied $(ls lambda/sql | wc -l) SQL files to lambda/sql/\"\n",
    "    ls -la lambda/sql/\n",
    "    echo \"‚úì SQL files prepared and temporary files cleaned up!\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Prepare Lambda Functions and Layer\n",
    "\n",
    "This step installs Node.js dependencies and packages all Lambda functions and the Lambda layer into ZIP files for AWS deployment. The script builds from source code to ensure security and freshness of dependencies. You'll see npm install output and ZIP file creation confirmations.\n",
    "\n",
    "‚ö†Ô∏è **Note**: The `image-processor-function` generates temporary pre-signed S3 URLs that expire after a short period for demonstration purpose. For production use, implement permanent URLs using S3 bucket hosting combined with [Amazon CloudFront CDN distribution](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-working-with.html) and appropriate IAM/bucket policies for secure, scalable image serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Lambda functions and layer from source\n",
    "import os\n",
    "\n",
    "zip_files = [\n",
    "    'lambda/lambda-layer.zip',\n",
    "    'lambda/xanadu-app-lambda-functions.zip',\n",
    "    'lambda/cors-lambda.zip',\n",
    "    'lambda/db-init-function.zip',\n",
    "    'lambda/image-processor-function.zip'\n",
    "]\n",
    "\n",
    "print(\"Building Lambda functions from source...\")\n",
    "\n",
    "# Remove existing ZIP files for security\n",
    "for zip_file in zip_files:\n",
    "    if os.path.exists(zip_file):\n",
    "        os.remove(zip_file)\n",
    "        print(f\"‚úì Removed existing {zip_file}\")\n",
    "\n",
    "# Install dependencies and create main Lambda function ZIP\n",
    "print(\"Installing dependencies for main Lambda function...\")\n",
    "!cd lambda/xanadu-app-lambda-functions && rm -rf node_modules && npm install --production --silent 2>/dev/null || npm install --production\n",
    "\n",
    "# Create ZIP with explicit inclusion of node_modules\n",
    "!cd lambda/xanadu-app-lambda-functions && zip -q -r ../xanadu-app-lambda-functions.zip . -x '*.git*'\n",
    "\n",
    "# Install dependencies and create Lambda Layer ZIP\n",
    "print(\"Installing dependencies for Lambda layer...\")\n",
    "!cd lambda/lambda-layer/nodejs && rm -rf node_modules && npm install --production --silent 2>/dev/null || npm install --production\n",
    "!cd lambda/lambda-layer && zip -q -r ../lambda-layer.zip .\n",
    "\n",
    "# Create other Lambda function ZIPs\n",
    "print(\"Creating other Lambda function packages...\")\n",
    "!cd lambda/cors-function && zip -q -r ../cors-lambda.zip .\n",
    "!cd lambda/db-init-function && zip -q -r ../db-init-function.zip .\n",
    "!cd lambda/image-processor-function && zip -q -r ../image-processor-function.zip .\n",
    "\n",
    "# Verify ZIP files were created and contain node_modules\n",
    "for zip_file in zip_files:\n",
    "    if os.path.exists(zip_file):\n",
    "        size = os.path.getsize(zip_file)\n",
    "        print(f\"‚úì {zip_file} created ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"‚úó {zip_file} not found\")\n",
    "\n",
    "# Verify main Lambda ZIP contains dependencies\n",
    "print(\"\\nVerifying Lambda ZIP contains node_modules:\")\n",
    "!unzip -l lambda/xanadu-app-lambda-functions.zip | grep -q node_modules && echo '‚úì node_modules found in ZIP' || echo '‚ö†Ô∏è node_modules not found'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create S3 Bucket\n",
    "\n",
    "Create an S3 bucket in your specified region to store Lambda deployment packages and application assets if you don't already have one. The bucket serves as the deployment artifact repository for CloudFormation. You'll see either a successful bucket creation message or an error if the bucket already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 bucket (if it doesn't exist)\n",
    "import os\n",
    "\n",
    "# Check if bucket exists\n",
    "check_result = os.system(f'aws s3api head-bucket --bucket {BUCKET_NAME} --region {REGION} 2>/dev/null')\n",
    "\n",
    "if check_result == 0:\n",
    "    print(f\"Bucket {BUCKET_NAME} already exists\")\n",
    "else:\n",
    "    # Create bucket with appropriate configuration\n",
    "    if REGION == 'us-east-1':\n",
    "        !aws s3api create-bucket --bucket $BUCKET_NAME --region $REGION\n",
    "    else:\n",
    "        !aws s3api create-bucket --bucket $BUCKET_NAME --region $REGION --create-bucket-configuration LocationConstraint=$REGION\n",
    "    print(f\"Created bucket {BUCKET_NAME} in region {REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Upload Lambda Code and Layer to S3\n",
    "\n",
    "Upload all packaged Lambda functions, the Lambda layer, SQL files, and product images to your S3 bucket. You'll see upload confirmations and directory listings showing successful file transfers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Lambda ZIP files to S3\n",
    "print(\"Uploading Lambda functions...\")\n",
    "!aws s3 cp lambda/lambda-layer.zip s3://$BUCKET_NAME/lambda-code/ --region $REGION --only-show-errors\n",
    "!aws s3 cp lambda/xanadu-app-lambda-functions.zip s3://$BUCKET_NAME/lambda-code/ --region $REGION --only-show-errors\n",
    "!aws s3 cp lambda/cors-lambda.zip s3://$BUCKET_NAME/lambda-code/ --region $REGION --only-show-errors\n",
    "!aws s3 cp lambda/db-init-function.zip s3://$BUCKET_NAME/lambda-code/ --region $REGION --only-show-errors\n",
    "!aws s3 cp lambda/image-processor-function.zip s3://$BUCKET_NAME/lambda-code/ --region $REGION --only-show-errors\n",
    "\n",
    "# Upload SQL files to S3\n",
    "print(\"Uploading SQL files...\")\n",
    "!aws s3 cp lambda/sql/ s3://$BUCKET_NAME/sql/ --recursive --region $REGION --only-show-errors\n",
    "\n",
    "# Upload product images to S3\n",
    "print(\"Uploading product images...\")\n",
    "!aws s3 cp images/ s3://$BUCKET_NAME/images/ --recursive --region $REGION --only-show-errors\n",
    "\n",
    "# Verify uploads (summary only)\n",
    "print(\"Upload verification:\")\n",
    "!aws s3 ls s3://$BUCKET_NAME/lambda-code/ --region $REGION | wc -l | xargs echo 'Lambda files:'\n",
    "!aws s3 ls s3://$BUCKET_NAME/sql/ --region $REGION | wc -l | xargs echo 'SQL files:'\n",
    "!aws s3 ls s3://$BUCKET_NAME/images/ --region $REGION | wc -l | xargs echo 'Image files:'\n",
    "\n",
    "print(\"‚úì Completed uploading Lambda functions, SQL files, and product images to S3!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Deploy CloudFormation Stack\n",
    "\n",
    "Deploy the comprehensive CloudFormation template that creates all AWS resources including Aurora PostgreSQL, Lambda functions, API Gateway, Cognito user pools, and Amplify hosting. The deployment uses the product images we downloaded and uploaded to S3 in the previous steps. You'll see CloudFormation deployment progress and completion status.\n",
    "\n",
    "‚ö†Ô∏è **Important for Separate Repository Users**: If you chose Option B (separate repository), you need to update the CloudFormation template first. See the code cell below for the required changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CloudFormation template needs updating for separate repository\n",
    "if 'REPO_TYPE' in locals() and REPO_TYPE == 'separate':\n",
    "    print(\"‚ö†Ô∏è  IMPORTANT: You're using a separate repository!\")\n",
    "    print(\"You need to update the CloudFormation template:\")\n",
    "    print(\"1. Open cfn/cloudformation-rewards-app.yaml\")\n",
    "    print(\"2. In the AmplifyApp BuildSpec section, remove these lines:\")\n",
    "    print(\"   - cd 3_Building_Your_First_Serverless_Web_App_with_Aurora/rewards-app-example\")\n",
    "    print(\"3. Change baseDirectory from:\")\n",
    "    print(\"   '3_Building_Your_First_Serverless_Web_App_with_Aurora/rewards-app-example/dist'\")\n",
    "    print(\"   to: 'dist'\")\n",
    "    print(\"4. Change cache paths from:\")\n",
    "    print(\"   '3_Building_Your_First_Serverless_Web_App_with_Aurora/rewards-app-example/node_modules/**/*'\")\n",
    "    print(\"   to: 'node_modules/**/*'\")\n",
    "    print(\"Press Enter after making these changes...\")\n",
    "    input()\n",
    "\n",
    "# Deploy CloudFormation stack\n",
    "print(f\"Deploying CloudFormation stack: {STACK_NAME}\")\n",
    "print(f\"This may take 15-20 minutes to complete...\")\n",
    "\n",
    "!aws cloudformation deploy \\\n",
    "  --template-file cfn/cloudformation-rewards-app.yaml \\\n",
    "  --s3-bucket $BUCKET_NAME \\\n",
    "  --stack-name $STACK_NAME \\\n",
    "  --region $REGION \\\n",
    "  --capabilities CAPABILITY_NAMED_IAM \\\n",
    "  --tags CreationSource=aws-database-cookbook-v2025.8 \\\n",
    "  --parameter-overrides \\\n",
    "    EnvironmentName=$ENVIRONMENT \\\n",
    "    S3BucketName=$BUCKET_NAME \\\n",
    "    GitHubOwner=$GITHUB_OWNER \\\n",
    "    GitHubRepo=$GITHUB_REPO \\\n",
    "    GitHubOAuthToken=$GITHUB_TOKEN \\\n",
    "    LambdaLayerS3Key=lambda-code/lambda-layer.zip \\\n",
    "    LambdaCodeS3Key=lambda-code/xanadu-app-lambda-functions.zip \\\n",
    "    LambdaCorsCodeS3Key=lambda-code/cors-lambda.zip \\\n",
    "    LambdaDBInitCodeS3Key=lambda-code/db-init-function.zip \\\n",
    "    LambdaImageUrlCodeS3Key=lambda-code/image-processor-function.zip\n",
    "\n",
    "print(\"‚úì CloudFormation stack deployment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Get CloudFormation Outputs\n",
    "\n",
    "Retrieve important output values from the deployed CloudFormation stack including API endpoints, Amplify URLs, database connection details, and resource identifiers. These outputs are essential for configuring the frontend application and testing the deployment. You'll see a formatted table displaying all stack outputs with their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CloudFormation outputs\n",
    "!aws cloudformation describe-stacks --stack-name $STACK_NAME --region $REGION --query \"Stacks[0].Outputs\" --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Update Environment Variables\n",
    "\n",
    "The following script automatically extracts CloudFormation stack outputs and updates the frontend application's environment configuration file with the correct API endpoints, authentication settings, and resource identifiers. The automation ensures the React application connects to the correct backend services. You'll see the environment file update confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the script executable and run it\n",
    "!chmod +x scripts/update-env.sh\n",
    "\n",
    "# Run the script to update .env file\n",
    "!./scripts/update-env.sh $STACK_NAME $REGION\n",
    "\n",
    "# Verify .env file was created\n",
    "import os\n",
    "if os.path.exists('.env'):\n",
    "    print(\"‚úì .env file created successfully\")\n",
    "    with open('.env', 'r') as f:\n",
    "        print(\"Contents:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"‚úó .env file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Build the Frontend\n",
    "\n",
    "The following script triggers an AWS Amplify build job that automatically builds and deploys the React frontend from your GitHub repository. The process includes installing dependencies, building the production bundle, and deploying to the Amplify hosting environment. You'll see build job status updates and completion confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Amplify App ID from CloudFormation outputs\n",
    "AMPLIFY_APP_ID = !aws cloudformation describe-stacks --stack-name $STACK_NAME --region $REGION --query \"Stacks[0].Outputs[?OutputKey=='AmplifyAppId'].OutputValue\" --output text\n",
    "AMPLIFY_APP_ID = AMPLIFY_APP_ID[0]\n",
    "\n",
    "# Start a new build job for the branch\n",
    "print(\"Starting a new build job for the main branch...\")\n",
    "!aws amplify start-job --app-id $AMPLIFY_APP_ID --branch-name main --job-type RELEASE --region $REGION --output json\n",
    "\n",
    "# Check Amplify build status in 60s intervals\n",
    "import json\n",
    "import time\n",
    "\n",
    "print(f\"Monitoring Amplify build status for app: {AMPLIFY_APP_ID}\")\n",
    "\n",
    "for i in range(10):\n",
    "    status_output = !aws amplify list-jobs --app-id $AMPLIFY_APP_ID --branch-name main --max-items 1 --region $REGION --query \"jobSummaries[0].status\" --output text\n",
    "    \n",
    "    if status_output and status_output[0] != 'None':\n",
    "        status = status_output[0]\n",
    "        print(f\"Check {i+1}/10 - Status: {status}\")\n",
    "        if status in ['SUCCEED', 'FAILED', 'CANCELLED']:\n",
    "            print(f\"Build completed with status: {status}\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Check {i+1}/10 - No jobs found\")\n",
    "    \n",
    "    if i < 9:\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Update Lambda Function (if needed)\n",
    "\n",
    "This optional step demonstrates how to update Lambda function code after the initial deployment by repackaging the function, uploading to S3, and updating the deployed function. This process is useful for iterative development and bug fixes without full stack redeployment. You'll see the function update confirmation and new version information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Lambda function name from CloudFormation outputs\n",
    "LAMBDA_FUNCTION_NAME = !aws cloudformation describe-stacks --stack-name $STACK_NAME --region $REGION --query \"Stacks[0].Outputs[?OutputKey=='ApiLambdaFunction'].OutputValue\" --output text\n",
    "\n",
    "# Rebuild Lambda function from source\n",
    "print(\"Rebuilding Lambda function from source...\")\n",
    "!cd lambda/xanadu-app-lambda-functions && npm install --production\n",
    "!cd lambda/xanadu-app-lambda-functions && zip -r ../xanadu-app-lambda-functions.zip .\n",
    "\n",
    "# Upload to S3\n",
    "!aws s3 cp lambda/xanadu-app-lambda-functions.zip s3://$BUCKET_NAME/lambda-code/ --region $REGION\n",
    "\n",
    "# Update the Lambda function\n",
    "!aws lambda update-function-code \\\n",
    "  --function-name $LAMBDA_FUNCTION_NAME \\\n",
    "  --s3-bucket $BUCKET_NAME \\\n",
    "  --s3-key lambda-code/xanadu-app-lambda-functions.zip \\\n",
    "  --region $REGION \\\n",
    "  --publish\n",
    "\n",
    "print(f\"Lambda function {LAMBDA_FUNCTION_NAME} updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Test the API Endpoints\n",
    "\n",
    "This step validates the deployed API by testing key endpoints including products and categories to ensure the backend services are functioning correctly. The tests verify database connectivity, Lambda function execution, and API Gateway routing. You'll see sample API responses demonstrating successful deployment and data retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API endpoint and API key from CloudFormation outputs\n",
    "API_ENDPOINT = !aws cloudformation describe-stacks --stack-name $STACK_NAME --region $REGION --query \"Stacks[0].Outputs[?OutputKey=='ApiEndpoint'].OutputValue\" --output text\n",
    "API_KEY = !aws cloudformation describe-stacks --stack-name $STACK_NAME --region $REGION --query \"Stacks[0].Outputs[?OutputKey=='ApiKey'].OutputValue\" --output text\n",
    "\n",
    "API_ENDPOINT = API_ENDPOINT[0] if API_ENDPOINT else 'Not found'\n",
    "API_KEY_ID = API_KEY[0] if API_KEY else 'Not found'\n",
    "\n",
    "print(f\"API Endpoint: {API_ENDPOINT}\")\n",
    "print(f\"API Key ID: {API_KEY_ID}\")\n",
    "\n",
    "# Get the actual API key value\n",
    "if API_KEY_ID != 'Not found':\n",
    "    API_KEY_VALUE = !aws apigateway get-api-key --api-key $API_KEY_ID --include-value --region $REGION --query 'value' --output text\n",
    "    API_KEY_VALUE = API_KEY_VALUE[0] if API_KEY_VALUE else 'Not found'\n",
    "    print(f\"API Key Value: {API_KEY_VALUE[:10]}...\")\n",
    "else:\n",
    "    API_KEY_VALUE = 'Not found'\n",
    "\n",
    "# Test products endpoint with API key\n",
    "print(\"\\nTesting API endpoints with API key...\")\n",
    "import json\n",
    "\n",
    "if API_ENDPOINT != 'Not found' and API_KEY_VALUE != 'Not found':\n",
    "    # Test products endpoint\n",
    "    products_output = !curl -s -H \"Content-Type: application/json\" -H \"X-API-Key: $API_KEY_VALUE\" $API_ENDPOINT/prod/products\n",
    "    \n",
    "    try:\n",
    "        products_response = products_output[0] if products_output else '{}'\n",
    "        products = json.loads(products_response)\n",
    "        \n",
    "        if \"products\" in products and len(products[\"products\"]) > 0:\n",
    "            print(f\"‚úì Products API working - found {len(products['products'])} products\")\n",
    "            print(\"Sample product:\")\n",
    "            print(json.dumps(products[\"products\"][0], indent=2))\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Products API response: {products_response[:200]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Products API test failed: {str(e)}\")\n",
    "        print(f\"Response: {products_response[:200] if 'products_response' in locals() else 'No response'}\")\n",
    "    \n",
    "    # Test categories endpoint\n",
    "    print(\"\\nTesting categories endpoint...\")\n",
    "    categories_output = !curl -s -H \"Content-Type: application/json\" -H \"X-API-Key: $API_KEY_VALUE\" $API_ENDPOINT/prod/category\n",
    "    \n",
    "    try:\n",
    "        categories_response = categories_output[0] if categories_output else '{}'\n",
    "        categories = json.loads(categories_response)\n",
    "        print(\"‚úì Categories API working:\")\n",
    "        print(json.dumps(categories, indent=2))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Categories API test failed: {str(e)}\")\n",
    "        print(f\"Response: {categories_response[:200] if 'categories_response' in locals() else 'No response'}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è API endpoint or API key not found in CloudFormation outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Create Test User\n",
    "\n",
    "This step creates a test user in Cognito User Pool using a random username from the Aurora database. The user will be created without email verification for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Get CloudFormation outputs\n",
    "cf = boto3.client('cloudformation', region_name=REGION)\n",
    "response = cf.describe_stacks(StackName=STACK_NAME)\n",
    "outputs = {o['OutputKey']: o['OutputValue'] for o in response['Stacks'][0]['Outputs']}\n",
    "\n",
    "# Get cluster ARN from Step 13 or construct it\n",
    "cluster_endpoint = outputs.get('ClusterEndpoint', '')\n",
    "if cluster_endpoint:\n",
    "    cluster_id = cluster_endpoint.split('.')[0]\n",
    "    account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "    cluster_arn = f\"arn:aws:rds:{REGION}:{account_id}:cluster:{cluster_id}\"\n",
    "else:\n",
    "    cluster_arn = f\"arn:aws:rds:{REGION}:{boto3.client('sts').get_caller_identity()['Account']}:cluster:{STACK_NAME}-{ENVIRONMENT}-cluster\"\n",
    "secret_arn = outputs['DBMasterUserSecretArn']\n",
    "user_pool_id = outputs['UserPoolId']\n",
    "\n",
    "# Get random username from database\n",
    "rds_data = boto3.client('rds-data', region_name=REGION)\n",
    "result = rds_data.execute_statement(\n",
    "    resourceArn=cluster_arn,\n",
    "    secretArn=secret_arn,\n",
    "    database='postgres',\n",
    "    sql=\"SELECT username FROM xpoints.customers ORDER BY random() LIMIT 1;\"\n",
    ")\n",
    "\n",
    "username = result['records'][0][0]['stringValue'] if result['records'] else \"diego_ramirez_130@example.com\"\n",
    "\n",
    "# Create Cognito user\n",
    "cognito = boto3.client('cognito-idp', region_name=REGION)\n",
    "try:\n",
    "    cognito.admin_create_user(\n",
    "        UserPoolId=user_pool_id,\n",
    "        Username=username,\n",
    "        TemporaryPassword='TempPass123!',\n",
    "        MessageAction='SUPPRESS',\n",
    "        UserAttributes=[\n",
    "            {'Name': 'email', 'Value': username},\n",
    "            {'Name': 'email_verified', 'Value': 'true'}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    cognito.admin_set_user_password(\n",
    "        UserPoolId=user_pool_id,\n",
    "        Username=username,\n",
    "        Password='TestPass123!',\n",
    "        Permanent=True\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Created test user: {username}\")\n",
    "    print(f\"   Password: TestPass123!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating user: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Access the Application\n",
    "\n",
    "Retrieve the public URL of your deployed Amplify application where users can access the complete Xanadu Rewards web application. The URL provides access to the fully functional React frontend connected to your serverless backend infrastructure. You'll see the clickable application URL for immediate testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Amplify URL from CloudFormation outputs\n",
    "print(f\"‚úÖ Created test user: {username}\")\n",
    "print(f\"   Password: TestPass123!\")\n",
    "print(\"Use the user and password above for testing purpose\")\n",
    "\n",
    "app_url=!aws cloudformation describe-stacks --stack-name $STACK_NAME --region $REGION --query \"Stacks[0].Outputs[?OutputKey=='AmplifyURL'].OutputValue\" --output text\n",
    "\n",
    "print(f\"‚úÖ Click Application URL to start exploring: {app_url[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: Monitoring and Troubleshooting\n",
    "\n",
    "This step demonstrates how to access CloudWatch logs for your Lambda functions to monitor application performance and troubleshoot issues. The commands show how to find log groups, identify recent log streams, and retrieve detailed execution logs. You'll see log group information and recent Lambda execution details for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Lambda function name from CloudFormation outputs\n",
    "LAMBDA_FUNCTION = !aws cloudformation describe-stacks --stack-name $STACK_NAME --region $REGION --query \"Stacks[0].Outputs[?OutputKey=='ApiLambdaFunction'].OutputValue\" --output text\n",
    "\n",
    "# View Lambda logs\n",
    "!aws logs describe-log-groups --log-group-name-prefix \"/aws/lambda/$LAMBDA_FUNCTION\" --region $REGION\n",
    "\n",
    "# Get the latest log stream\n",
    "LOG_STREAM = !aws logs describe-log-streams --log-group-name \"/aws/lambda/$LAMBDA_FUNCTION\" --region $REGION --order-by LastEventTime --descending --limit 1 --query \"logStreams[0].logStreamName\" --output text\n",
    "\n",
    "# View logs\n",
    "!aws logs get-log-events --log-group-name \"/aws/lambda/$LAMBDA_FUNCTION\" --log-stream-name \"$LOG_STREAM\" --region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 17: Cleanup\n",
    "\n",
    "This cleanup step safely removes all AWS resources created during the deployment by deleting the CloudFormation stack, which automatically handles resource dependencies and cleanup order. The process includes waiting for complete stack deletion to ensure all resources are properly removed. You'll see deletion progress and completion confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete main stack\n",
    "!aws cloudformation delete-stack --stack-name $STACK_NAME --region $REGION\n",
    "\n",
    "# Wait for stack deletion to complete\n",
    "!aws cloudformation wait stack-delete-complete --stack-name $STACK_NAME --region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have successfully deployed the Xanadu Rewards Application on AWS with enhanced security features. The application includes:\n",
    "\n",
    "1. A React frontend hosted on AWS Amplify\n",
    "2. A serverless backend using AWS Lambda and API Gateway\n",
    "3. Authentication using Amazon Cognito\n",
    "4. Database using Amazon Aurora PostgreSQL Serverless v2\n",
    "5. Connection pooling using Amazon RDS Proxy\n",
    "\n",
    "### Security Enhancements Implemented:\n",
    "- ‚úì Lambda functions built from source code (no pre-built packages)\n",
    "- ‚úì Product images downloaded from AWS Workshop Studio during deployment\n",
    "- ‚úì SQL files downloaded from official workshop source\n",
    "- ‚úì No sensitive files stored in repository\n",
    "- ‚úì Fresh dependency installation for each deployment\n",
    "\n",
    "You can now access the application using the Amplify URL and sign in with the test user you created.\n",
    "\n",
    "## Additional Resources üìö\n",
    "\n",
    "### Deployment & Infrastructure\n",
    "- [AWS Amplify Documentation](https://docs.aws.amazon.com/amplify/)\n",
    "- [CloudFormation User Guide](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/)\n",
    "- [AWS Lambda Developer Guide](https://docs.aws.amazon.com/lambda/latest/dg/)\n",
    "\n",
    "### Database & Backend\n",
    "- [Aurora Serverless v2](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html)\n",
    "- [RDS Proxy](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html)\n",
    "- [API Gateway](https://docs.aws.amazon.com/apigateway/latest/developerguide/)\n",
    "\n",
    "### Authentication & Security\n",
    "- [Amazon Cognito](https://docs.aws.amazon.com/cognito/latest/developerguide/)\n",
    "- [IAM Best Practices](https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html)\n",
    "- [AWS Security Best Practices](https://aws.amazon.com/architecture/security-identity-compliance/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
