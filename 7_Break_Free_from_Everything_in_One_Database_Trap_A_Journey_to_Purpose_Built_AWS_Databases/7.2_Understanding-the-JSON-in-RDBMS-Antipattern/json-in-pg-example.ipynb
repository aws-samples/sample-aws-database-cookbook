{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the JSON Antipattern with Example\n",
    "\n",
    "<div style=\"background-color: #f8f9fa; border: 1px solid #e9ecef; border-radius: 8px; padding: 10px; margin: 10px;\">\n",
    "<strong>üìã Workshop Contents</strong>\n",
    "<ul style=\"line-height: 1.2;\">\n",
    "<li><a href=\"#1-Initial-Setup\">1. Initial Setup</a>\n",
    "  <ul>\n",
    "    <li><a href=\"#Creating-the-Table-Structure\">Creating the Table Structure</a></li>\n",
    "    <li><a href=\"#Whats-Happening-Here\">What's Happening Here?</a></li>\n",
    "    <li><a href=\"#GIN-Generalized-Inverted-Index\">GIN (Generalized Inverted Index)</a></li>\n",
    "    <li><a href=\"#Field-Specific-Indexing\">Field-Specific Indexing</a></li>\n",
    "    <li><a href=\"#Create-Supporting-Functions\">Create Supporting Functions</a></li>\n",
    "  </ul>\n",
    "</li>\n",
    "<li><a href=\"#2-Data-Generation\">2. Data Generation</a>\n",
    "  <ul>\n",
    "    <li><a href=\"#Executing-the-Data-Generation-Procedure\">Executing the Data Generation Procedure</a></li>\n",
    "    <li><a href=\"#Data-Visualization\">Data Visualization</a></li>\n",
    "  </ul>\n",
    "</li>\n",
    "<li><a href=\"#3-Performance-Analysis\">3. Performance Analysis</a></li>\n",
    "<li><a href=\"#Conclusion-The-Case-for-Purpose-Built-Databases\">Conclusion: The Case for Purpose-Built Databases</a></li>\n",
    "<li><a href=\"#Next-Steps\">Next Steps</a></li>\n",
    "<li><a href=\"#Additional-Resources\">Additional Resources üìö</a></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Setup\n",
    "\n",
    "Let's walk through an example to demonstrate how storing and querying JSON data in PostgreSQL can lead to performance challenges. We'll create a table that stores customer activity data as JSON, populate it with test data, and analyze query performance.\n",
    "\n",
    "**Important:** Open your favorite SQL editor and connect to a PostgreSQL database (RDS/Aurora) that you have access to test the code examples below. \n",
    "\n",
    "‚ö†Ô∏è **Precaution:** Do not use production databases for this exercise. Use development databases and schemas that you are responsible for to avoid any disruptions to live systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Table Structure\n",
    "First, let's create a table that stores customer activities as JSON documents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a customer activities table with JSONB storage and appropriate indexes to demonstrate JSON data handling in PostgreSQL. The table structure includes a primary key, customer identifier, JSON activity data, and timestamp fields with GIN and expression indexes for query optimization with table creation confirmation and index setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE customer_activities (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    customer_id INTEGER,\n",
    "    activity_data JSONB,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Create indexes for better performance\n",
    "CREATE INDEX idx_activity_data_gin ON customer_activities USING GIN (activity_data);\n",
    "CREATE INDEX idx_activity_type ON customer_activities ((activity_data->>'activity_type'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/7.2-postgresql-table-structure.png\" alt=\"pg-table\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JSON Document Structure|100](../images/7.2-json-data-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JSON Document Structure](../images/7.2-json-data-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Happening Here?\n",
    "\n",
    "### Table Structure\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| `id` | SERIAL | Auto-incrementing primary key |\n",
    "| `customer_id` | INTEGER | Field to identify customers |\n",
    "| `activity_data` | JSONB | Field to store activity information |\n",
    "| `created_at` | TIMESTAMP | When the record was created |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIN (Generalized Inverted Index)\n",
    "\n",
    "GIN indexes are ideal for JSONB columns containing complex JSON documents that need to be queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE INDEX idx_activity_data_gin ON customer_activities USING GIN (activity_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This index type:\n",
    "- Enables efficient full document searches\n",
    "- Supports containment operators (`@>`, `?`, `?&`, `?|`)\n",
    "- Works well with JSONB but has higher insertion overhead\n",
    "\n",
    "### Field-Specific Indexing\n",
    "\n",
    "For frequently queried specific JSON fields, create targeted indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE INDEX idx_activity_type ON customer_activities ((activity_data->>'activity_type'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits:\n",
    "- Faster queries on specific JSON fields\n",
    "- Smaller index size compared to full GIN indexes\n",
    "- Better performance for equality and range queries on the indexed field\n",
    "\n",
    "‚ö†Ô∏è **Warning**: While PostgreSQL's JSON capabilities are powerful, using JSON/JSONB for large-scale document storage may impact performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Supporting Functions\n",
    "Now we'll create a procedure that generates millions of sample JSON records to simulate a production environment. This will help us demonstrate how performance degrades as data volume increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate realistic JSON activity data with randomized activity types, devices, timestamps, and values to simulate production-like customer behavior patterns. The function uses PostgreSQL's jsonb_build_object to create structured JSON documents with consistent schema for testing purposes and can generate millions of test records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION generate_random_activity_data()\n",
    "RETURNS JSONB AS $$\n",
    "DECLARE\n",
    "    activities TEXT[] := ARRAY['login', 'purchase', 'view_product'];\n",
    "    devices TEXT[] := ARRAY['mobile', 'desktop', 'tablet'];\n",
    "BEGIN\n",
    "    RETURN jsonb_build_object(\n",
    "        'activity_type', activities[floor(random() * 3 + 1)],\n",
    "        'device', devices[floor(random() * 3 + 1)],\n",
    "        'timestamp', now(),\n",
    "        'value', random() * 1000\n",
    "    );\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiently generate large volumes of test data by inserting specified numbers of customer activity records with randomized customer IDs and JSON activity data. The procedure uses a loop to create realistic datasets for performance testing, distributing activities across 1000 different customers with procedure creation confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create procedure for data generation\n",
    "CREATE OR REPLACE PROCEDURE generate_test_data(p_records INTEGER)\n",
    "LANGUAGE plpgsql AS $$\n",
    "BEGIN\n",
    "    FOR i IN 1..p_records LOOP\n",
    "        INSERT INTO customer_activities (customer_id, activity_data)\n",
    "        VALUES (\n",
    "            floor(random() * 1000),\n",
    "            generate_random_activity_data()\n",
    "        );\n",
    "    END LOOP;\n",
    "END;\n",
    "$$;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the Data Generation Procedure\n",
    "\n",
    "After creating our procedures, we now need to execute it to populate our table. We'll insert one million records to simulate a realistic production dataset where performance issues typically emerge. \n",
    "A million records is actually modest compared to many production systems, but enough to highlight performance characteristics. Depending on your hardware, this operation may take several minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the data generation procedure to insert one million customer activity records, creating a substantial dataset for performance analysis and demonstrating real-world scale challenges. The operation may take several minutes depending on hardware capabilities and will populate the table with diverse JSON documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Execute procedure to insert 1 million records\n",
    "CALL generate_test_data(1000000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "Below is a screenshot showing how our test data appears in PostgreSQL. Notice how the `activity_data` column stores complex JSON documents within a traditional relational table structure:\n",
    "\n",
    "As you can see, each row contains a JSON document with multiple nested fields. While PostgreSQL displays this data neatly in the query results, internally it's processing this semi-structured data differently than traditional relational data. This storage approach creates additional overhead for:\n",
    "\n",
    "\n",
    "<img src=\"../images/7.2-json-data-example.png\" alt=\"JSON Document Structure\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Analysis\n",
    "\n",
    "Now that we have a substantial dataset, let's run some analytical queries to demonstrate how PostgreSQL handles complex JSON data operations. As the complexity of queries increases, we'll see performance degradation that would be less pronounced in purpose-built document databases.\n",
    "\n",
    "### Query Example: User Activity Analysis by Device Type\n",
    "\n",
    "The following query analyzes customer activities by finding all mobile device activities, grouping them by customer and activity type, and counting occurrences. This represents a common analytical scenario in real-world applications:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate PostgreSQL's JSON query performance by filtering mobile device activities, grouping by customer and activity type, and counting occurrences with execution plan analysis. The EXPLAIN ANALYZE command reveals query costs, execution time, and index usage patterns to illustrate performance characteristics of JSON operations at scale with detailed execution statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Example of slow-performing query with execution plan\n",
    "EXPLAIN ANALYZE\n",
    "SELECT \n",
    "    customer_id,\n",
    "    activity_data->>'activity_type' as activity_type,\n",
    "    COUNT(*) as activity_count\n",
    "FROM customer_activities\n",
    "WHERE activity_data->>'device' = 'mobile'\n",
    "GROUP BY customer_id, activity_data->>'activity_type';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: The Case for Purpose-Built Databases\n",
    "\n",
    "As our example demonstrates, while PostgreSQL can store and query JSON data, this approach shows clear limitations when dealing with:\n",
    "\n",
    "- Large volumes of document data\n",
    "- Complex nested JSON structures\n",
    "- Analytical queries with multiple JSON operations\n",
    "- High-throughput applications\n",
    "\n",
    "The performance issues we've observed aren't due to PostgreSQL being a poor database system‚Äîquite the contrary. The challenge stems from using a relational database for workloads it wasn't optimized to handle. This is the essence of the antipattern we're addressing.\n",
    "\n",
    "### Looking Forward: Choosing the Right Database\n",
    "\n",
    "In the next section, we'll explore how to select appropriate purpose-built databases for different data workloads. We'll cover migration strategies, performance comparisons, and architectural best practices to help you implement a multi-database strategy that aligns with modern application needs.\n",
    "\n",
    "> üí° **Key Takeaway**: The \"one database for everything\" approach often leads to performance and scalability issues. Modern applications benefit from using the right database for the right workload, even if it means managing multiple database systems.\n",
    "\n",
    "Stay tuned as we dive deeper into database selection criteria and migration pathways to move from antipatterns to optimized architectures.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you've experienced the JSON antipattern firsthand, proceed to explore purpose-built database solutions:\n",
    "\n",
    "- **[7.3 Choosing the Right Database for Your Workload](../7.3_Migration-Strategies/README.md)** - Learn database selection criteria and decision frameworks\n",
    "- **[7.3 Migration Strategies: PostgreSQL to DocumentDB](../7.3_Migration-Strategies/migrate-pg-docdb.ipynb)** - Learn practical migration approaches and implementation strategies\n",
    "\n",
    "## Additional Resources üìö\n",
    "\n",
    "### PostgreSQL JSON Features\n",
    "- [PostgreSQL JSON Types](https://www.postgresql.org/docs/current/datatype-json.html)\n",
    "- [JSON Functions and Operators](https://www.postgresql.org/docs/current/functions-json.html)\n",
    "- [GIN Indexes for JSON](https://www.postgresql.org/docs/current/gin-intro.html)\n",
    "\n",
    "### Purpose-Built Databases\n",
    "- [Amazon DocumentDB](https://docs.aws.amazon.com/documentdb/)\n",
    "- [Amazon DynamoDB](https://docs.aws.amazon.com/dynamodb/)\n",
    "- [Database Selection Guide](https://aws.amazon.com/products/databases/)\n",
    "\n",
    "### Performance & Migration\n",
    "- [Database Migration Best Practices](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_BestPractices.html)\n",
    "- [Performance Tuning PostgreSQL](https://wiki.postgresql.org/wiki/Performance_Optimization)\n",
    "- [AWS Database Migration Service](https://docs.aws.amazon.com/dms/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
