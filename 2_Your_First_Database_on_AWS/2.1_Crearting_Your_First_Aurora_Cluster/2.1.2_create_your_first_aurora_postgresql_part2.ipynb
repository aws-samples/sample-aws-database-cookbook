{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e87785",
   "metadata": {},
   "source": [
    "# Creating Your First Aurora Cluster - Part 2\n",
    "\n",
    "<div style=\"background-color: #f8f9fa; border: 1px solid #e9ecef; border-radius: 8px; padding: 10px; margin: 10px;\">\n",
    "<strong>📋 Workshop Contents</strong>\n",
    "<ul style=\"line-height: 1.2;\">\n",
    "<li><a href=\"#What-Well-Build\">What We'll Build</a></li>\n",
    "<li><a href=\"#Prerequisite\">Prerequisite</a></li>\n",
    "<li><a href=\"#Cost-Overview\">Cost Overview</a></li>\n",
    "<li><a href=\"#Visual-Guide-to-Aurora-Console\">Visual Guide to Aurora Console</a></li>\n",
    "<li><a href=\"#Step-1-Create-IAM-Roles\">Step 1: Create IAM Roles</a></li>\n",
    "<li><a href=\"#Step-2-Create-DB-Subnet-Group\">Step 2: Create DB Subnet Group</a></li>\n",
    "<li><a href=\"#Step-3-Create-Parameter-Groups\">Step 3: Create Parameter Groups</a></li>\n",
    "<li><a href=\"#Step-4-Create-Aurora-Cluster\">Step 4: Create Aurora Cluster</a></li>\n",
    "<li><a href=\"#Step-5-Associate-S3-Import-Role\">Step 5: Associate S3 Import Role</a></li>\n",
    "<li><a href=\"#Step-6-Create-Writer-and-Reader-Instances\">Step 6: Create Writer and Reader Instances</a></li>\n",
    "<li><a href=\"#Step-7-Network-Diagnostics-and-Troubleshooting\">Step 7: Network Diagnostics and Troubleshooting</a></li>\n",
    "<li><a href=\"#Summary-and-Resources-Created\">Summary and Resources Created</a></li>\n",
    "<li><a href=\"#Cleanup\">Cleanup</a></li>\n",
    "<li><a href=\"#Next-Steps\">Next Steps</a></li>\n",
    "<li><a href=\"#Additional-Resources\">Additional Resources</a></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "> **💡 Quick Start Available**: Want to skip the manual setup on **networking and database creation**? Launch the infrastructure with our [AWS CloudFormation template](../cfn/aurora-complete-stack.yml). If you have [set up networking already](2.1.1_create_your_first_aurora_postgresql_part1.ipynb), launch Aurora Serverless v2 with our [AWS CloudFormation template](https://console.aws.amazon.com/cloudformation/home/#stacks/create/template?stackName=AuroraServerlessV2&templateSource=Upload) - download the [template file](../cfn/aurora-serverless-v2.yml) first and upload it. Feel free to explore from the [AWS console](https://console.aws.amazon.com/rds) for what you have created. Then, go to [the next section to connect to your database](../2.2_Connecting_to_Your_Aurora_PostgreSQL/README.MD).\n",
    "\n",
    "## What We'll Build\n",
    "\n",
    "- [**✅ Network Setup**: VPC with public/private subnets across 2 AZs, routing, private subnet isolation, and security groups](./2.1.1_create_your_first_aurora_postgresql_part1.ipynb)\n",
    "- **Database Layer**: Aurora PostgreSQL Serverless v2 cluster with writer and reader instances\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting this workshop, ensure you have:\n",
    "\n",
    "- ✅ **Networking Foundation**: Complete networking setup from either:\n",
    "  - [SageMaker Notebook CloudFormation template](../../1_Getting_Started_with_AWS/cfn/sagemaker-notebook-template.yaml) (automated setup)\n",
    "  - [Part 1: Create VPC and Networking](./2.1.1_create_your_first_aurora_postgresql_part1.ipynb) (manual setup)\n",
    "- ✅ **AWS Account**: Active AWS account with appropriate permissions\n",
    "  - [Create your first AWS account](../1_Getting_Started_with_AWS/README.MD) if you have not.\n",
    "- ✅ **Jupyter Environment**: This notebook should be run in:\n",
    "  - [Amazon SageMaker Jupyter notebook (recommended)](../../1_Getting_Started_with_AWS/1.4_Setting_up_Your_Cookbook_Environment/README.MD)\n",
    "  - Or, local Jupyter with AWS CLI configured. Ensure [database access from your local Jupyter](../../1_Getting_Started_with_AWS/1.4_Setting_up_Your_Cookbook_Environment/README.MD).\n",
    "- ✅ **IAM Permissions** for:\n",
    "  - RDS cluster and instance creation/management\n",
    "  - IAM role creation and policy attachment\n",
    "  - Secrets Manager operations\n",
    "  - Parameter group management\n",
    "- ✅ **AWS CLI**: Configured with credentials and default region\n",
    "  - [Amazon SageMaker Jupyter notebook (recommended)](../../1_Getting_Started_with_AWS/1.4_Setting_up_Your_Cookbook_Environment/README.MD) has an IAM role with permissions to access relevant resources. \n",
    "\n",
    "> 💡 **Note**: This notebook creates the Aurora PostgreSQL cluster. You'll connect to it in [Section 2.2](../2.2_Connecting_to_Your_Aurora_PostgreSQL/README.MD).\n",
    "\n",
    "## Cost Overview 💰\n",
    "\n",
    "Use [AWS Pricing Calculator](https://calculator.aws/#/) to estimate the cost for your architecture solution. The following a rough cost estimation for the resources created in this notebook.\n",
    "\n",
    "| Component | Cost (us-east-1) | Notes |\n",
    "|-----------|------------------|--------|\n",
    "| Aurora Serverless v2 | \\$0.12/ACU-hour | Minimum 0 ACUs with auto-pause |\n",
    "| Storage | \\$0.10/GB-month (standard) | Starts at 10GB, scales automatically |\n",
    "| Backup | First day free | Keep retention at 1 day for free backups |\n",
    "| Data API | \\$0.35/million requests | HTTP endpoint for serverless applications |\n",
    "\n",
    "💡 **Cost Optimization Tips:**\n",
    "- Use auto-pause feature to allow [scaling down to 0 ACU](https://aws.amazon.com/blogs/database/introducing-scaling-to-0-capacity-with-amazon-aurora-serverless-v2/) for cost saving when database is idle\n",
    "- Set appropriate min/max ACU values based on workload\n",
    "- Leverage free tier features, such as [Performance Insights](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_PerfInsights.Overview.html) with 7 days metrics retention period, 1 day [automatic backup retention](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Backups.Retaining.html) for Point-in-Time recovery.\n",
    "- If the workload is not I/O intensive during testing phase, use standard storage instead of [I/O optimized](https://aws.amazon.com/blogs/aws/new-amazon-aurora-i-o-optimized-cluster-configuration-with-up-to-40-cost-savings-for-i-o-intensive-applications/).\n",
    "- Data API is ideal for serverless applications with infrequent database access patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3eb9af",
   "metadata": {},
   "source": [
    "## Visual Guide to Aurora Console\n",
    "\n",
    "### Creating Aurora Cluster\n",
    "*Step-by-step console walkthrough of creating an Aurora cluster*\n",
    "\n",
    "![Creating Aurora Cluster](../images/2.1-create-aurora-cluster-console.gif)\n",
    "\n",
    "### Exploring Aurora Console\n",
    "*Overview of key Aurora console features:*\n",
    "- Configuration settings\n",
    "- Chat with Amazon Q for best practice suggestions based on your particular settings\n",
    "\n",
    "![Exploring Aurora Console](../images/2.1-explore-aurora-cluster-console.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f2a77",
   "metadata": {},
   "source": [
    "## Step-by-step Guidance\n",
    "\n",
    "The following steps will create a complete Aurora PostgreSQL Serverless v2 cluster with production-ready features:\n",
    "\n",
    "- **IAM Roles**: S3 import and enhanced monitoring capabilities\n",
    "- **Network Configuration**: Database subnet groups and security settings\n",
    "- **Security**: Secrets Manager integration for credential management\n",
    "- **Database Setup**: Aurora cluster with custom parameter groups\n",
    "- **Instances**: Writer and reader instances with Performance Insights\n",
    "- **Diagnostics**: Network and cluster health verification\n",
    "\n",
    "## Step 1: Create IAM Roles\n",
    "\n",
    "Create essential IAM roles that Aurora will use for S3 data import operations. The S3 import role allows Aurora to read data from S3 buckets. You'll see the ARNs for the role created in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create IAM role for S3 import\n",
    "echo \"Creating IAM role for S3 import...\"\n",
    "aws iam create-role \\\n",
    "    --role-name aurora-s3-import-role \\\n",
    "    --assume-role-policy-document '{\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": \"rds.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }]\n",
    "    }' \\\n",
    "    --tags Key=CreationSource,Value=aws-database-cookbook-v2025.8\n",
    "\n",
    "# Attach S3 read policy to the role\n",
    "aws iam attach-role-policy \\\n",
    "    --role-name aurora-s3-import-role \\\n",
    "    --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\n",
    "\n",
    "# Get the role ARN for later use\n",
    "S3_ROLE_ARN=$(aws iam get-role --role-name aurora-s3-import-role --query 'Role.Arn' --output text)\n",
    "echo \"S3 Import Role ARN: $S3_ROLE_ARN\"\n",
    "\n",
    "# Create IAM role for enhanced monitoring\n",
    "echo \"Creating IAM role for enhanced monitoring...\"\n",
    "aws iam create-role \\\n",
    "    --role-name aurora-monitoring-role \\\n",
    "    --assume-role-policy-document '{\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": \"monitoring.rds.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }]\n",
    "    }' \\\n",
    "    --tags Key=CreationSource,Value=aws-database-cookbook-v2025.8\n",
    "\n",
    "# Attach enhanced monitoring policy\n",
    "aws iam attach-role-policy \\\n",
    "    --role-name aurora-monitoring-role \\\n",
    "    --policy-arn arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\n",
    "\n",
    "# Get monitoring role ARN\n",
    "MONITORING_ROLE_ARN=$(aws iam get-role --role-name aurora-monitoring-role --query 'Role.Arn' --output text)\n",
    "echo \"Monitoring Role ARN: $MONITORING_ROLE_ARN\"\n",
    "\n",
    "# Save for use in other cells\n",
    "echo \"export S3_ROLE_ARN=$S3_ROLE_ARN\" > .aurora_vars\n",
    "echo \"export MONITORING_ROLE_ARN=$MONITORING_ROLE_ARN\" >> .aurora_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b9d01f",
   "metadata": {},
   "source": [
    "## Step 2: Create DB Subnet Group\n",
    "\n",
    "> **💡 Important**: Before proceeding, make sure you have the private subnet IDs available. Check the private subnets first to set these environmental variables.\n",
    "\n",
    "### Detect Private Subnets\n",
    "\n",
    "Run the cell below to detect and set the private subnet variables needed for the Aurora cluster.\n",
    "\n",
    "The following script automatically detects your VPC configuration by checking for CloudFormation stacks and retrieving private subnet IDs needed for Aurora cluster creation. The commands search for existing cookbook or aurora stacks and extract subnet information from either CloudFormation outputs or direct VPC queries. You'll see the detected private subnet IDs that will be used for the Aurora database subnet group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# First, check for SageMaker notebook CloudFormation stack\n",
    "SAGEMAKER_STACK=$(aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE --query \"StackSummaries[?contains(StackName, 'SagemakerJupyterNotebook') || contains(StackName, 'cookbook')].StackName\" --output text | head -1)\n",
    "\n",
    "if [ ! -z \"$SAGEMAKER_STACK\" ]; then\n",
    "    echo \"Found SageMaker notebook CloudFormation stack: $SAGEMAKER_STACK\"\n",
    "    # Get VPC ID from SageMaker stack\n",
    "    VPC_ID=$(aws cloudformation describe-stacks --stack-name $SAGEMAKER_STACK --query \"Stacks[0].Outputs[?OutputKey=='VpcId'].OutputValue\" --output text)\n",
    "    \n",
    "    if [ ! -z \"$VPC_ID\" ] && [ \"$VPC_ID\" != \"None\" ]; then\n",
    "        echo \"Using SageMaker notebook VPC: $VPC_ID\"\n",
    "        # Get private subnets from the SageMaker VPC\n",
    "        PRIVATE_SUBNET_A=$(aws cloudformation describe-stacks --stack-name $SAGEMAKER_STACK --query \"Stacks[0].Outputs[?OutputKey=='PrivateSubnetA'].OutputValue\" --output text)\n",
    "        PRIVATE_SUBNET_B=$(aws cloudformation describe-stacks --stack-name $SAGEMAKER_STACK --query \"Stacks[0].Outputs[?OutputKey=='PrivateSubnetB'].OutputValue\" --output text)\n",
    "        \n",
    "        if [ ! -z \"$PRIVATE_SUBNET_A\" ] && [ ! -z \"$PRIVATE_SUBNET_B\" ]; then\n",
    "            echo \"Found private subnets from SageMaker stack:\"\n",
    "            echo \"PRIVATE_SUBNET_A: $PRIVATE_SUBNET_A\"\n",
    "            echo \"PRIVATE_SUBNET_B: $PRIVATE_SUBNET_B\"\n",
    "            \n",
    "            # Get database security group from CloudFormation\n",
    "            SG_ID=$(aws cloudformation describe-stacks --stack-name $SAGEMAKER_STACK --query \"Stacks[0].Outputs[?OutputKey=='DatabaseSecurityGroup'].OutputValue\" --output text)\n",
    "            if [ ! -z \"$SG_ID\" ] && [ \"$SG_ID\" != \"None\" ]; then\n",
    "                echo \"Found database security group from CloudFormation: $SG_ID\"\n",
    "            fi\n",
    "        else\n",
    "            echo \"Private subnets not found in CloudFormation stack\"\n",
    "        fi\n",
    "    else\n",
    "        echo \"VPC not found in CloudFormation stack\"\n",
    "    fi\n",
    "else\n",
    "    echo \"No SageMaker CloudFormation stack found\"\n",
    "fi\n",
    "\n",
    "# If subnets not found from SageMaker stack, check for manually created VPC\n",
    "if [ -z \"$PRIVATE_SUBNET_A\" ] || [ -z \"$PRIVATE_SUBNET_B\" ]; then\n",
    "    echo \"Looking for manually created subnets with aurora-private tags...\"\n",
    "    PRIVATE_SUBNET_A=$(aws ec2 describe-subnets --filters \"Name=tag:Name,Values=aurora-private-1a\" --query \"Subnets[0].SubnetId\" --output text)\n",
    "    PRIVATE_SUBNET_B=$(aws ec2 describe-subnets --filters \"Name=tag:Name,Values=aurora-private-1b\" --query \"Subnets[0].SubnetId\" --output text)\n",
    "    \n",
    "    if [ ! -z \"$PRIVATE_SUBNET_A\" ] && [ \"$PRIVATE_SUBNET_A\" != \"None\" ] && [ ! -z \"$PRIVATE_SUBNET_B\" ] && [ \"$PRIVATE_SUBNET_B\" != \"None\" ]; then\n",
    "        echo \"Found manually created private subnets:\"\n",
    "        echo \"PRIVATE_SUBNET_A: $PRIVATE_SUBNET_A\"\n",
    "        echo \"PRIVATE_SUBNET_B: $PRIVATE_SUBNET_B\"\n",
    "        # Get VPC ID from the manually created subnets\n",
    "        VPC_ID=$(aws ec2 describe-subnets --subnet-ids $PRIVATE_SUBNET_A --query 'Subnets[0].VpcId' --output text)\n",
    "        \n",
    "        # Create security group for manual setup\n",
    "        if [ -z \"$SG_ID\" ] || [ \"$SG_ID\" == \"None\" ]; then\n",
    "            echo \"Creating security group for Aurora database...\"\n",
    "            SG_ID=$(aws ec2 create-security-group \\\n",
    "                --group-name aurora-sg \\\n",
    "                --description \"Security group for Aurora cluster\" \\\n",
    "                --vpc-id $VPC_ID \\\n",
    "                --tag-specifications 'ResourceType=security-group,Tags=[{Key=Name,Value=aurora-sg}]' \\\n",
    "                --query 'GroupId' \\\n",
    "                --output text)\n",
    "            \n",
    "            # Add inbound rule for PostgreSQL from VPC\n",
    "            aws ec2 authorize-security-group-ingress \\\n",
    "                --group-id $SG_ID \\\n",
    "                --protocol tcp \\\n",
    "                --port 5432 \\\n",
    "                --cidr $(aws ec2 describe-vpcs --vpc-ids $VPC_ID --query 'Vpcs[0].CidrBlock' --output text)\n",
    "            \n",
    "            echo \"Created security group: $SG_ID\"\n",
    "        fi\n",
    "    else\n",
    "        echo \"Could not find private subnets. Please run Part 1 first or use CloudFormation template.\"\n",
    "        exit 1\n",
    "    fi\n",
    "fi\n",
    "\n",
    "# Save environment variables\n",
    "echo \"export PRIVATE_SUBNET_A=$PRIVATE_SUBNET_A\" > .env_vars\n",
    "echo \"export PRIVATE_SUBNET_B=$PRIVATE_SUBNET_B\" >> .env_vars\n",
    "echo \"export VPC_ID=$VPC_ID\" >> .env_vars\n",
    "echo \"export SAGEMAKER_STACK=$SAGEMAKER_STACK\" >> .env_vars\n",
    "echo \"export SG_ID=$SG_ID\" >> .env_vars\n",
    "\n",
    "echo \"Using VPC: $VPC_ID\"\n",
    "echo \"Environment variables saved to .env_vars\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ff44d",
   "metadata": {},
   "source": [
    "### Create subnet groups\n",
    "\n",
    "Create a database subnet group that specifies which private subnets Aurora can use for database instances, ensuring proper network isolation and multi-AZ deployment. The subnet group associates the previously created private subnets with descriptive tags for resource management. You'll see the subnet group creation confirmation with associated subnet details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028fec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Source environment variables\n",
    "source .env_vars\n",
    "\n",
    "# Generate unique suffix for subnet group\n",
    "SUBNET_GROUP_SUFFIX=$(date +%s | tail -c 6)\n",
    "SUBNET_GROUP_NAME=\"aurora-subnet-group-$SUBNET_GROUP_SUFFIX\"\n",
    "\n",
    "echo \"Creating DB subnet group with name: $SUBNET_GROUP_NAME\"\n",
    "aws rds create-db-subnet-group \\\n",
    "    --db-subnet-group-name $SUBNET_GROUP_NAME \\\n",
    "    --db-subnet-group-description \"Subnet group for Aurora cluster\" \\\n",
    "    --subnet-ids \"$PRIVATE_SUBNET_A\" \"$PRIVATE_SUBNET_B\" \\\n",
    "    --tags Key=Environment,Value=Development\n",
    "\n",
    "# Save subnet group name to .env_vars for later usage\n",
    "echo \"export SUBNET_GROUP_NAME=$SUBNET_GROUP_NAME\" >> .env_vars\n",
    "\n",
    "# Verify subnet group creation\n",
    "aws rds describe-db-subnet-groups \\\n",
    "    --db-subnet-group-name $SUBNET_GROUP_NAME \\\n",
    "    --query 'DBSubnetGroups[0].{Name:DBSubnetGroupName,Status:SubnetGroupStatus,Subnets:Subnets[*].SubnetIdentifier}' \\\n",
    "    --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaa0386",
   "metadata": {},
   "source": [
    "## Step 3: Create Parameter Groups\n",
    "\n",
    "Create custom parameter groups for both Aurora cluster and database instance levels, allowing fine-tuned configuration of PostgreSQL settings and security parameters. The parameter groups enable SSL enforcement and performance monitoring extensions like pg_stat_statements. You'll see parameter group creation confirmations and configuration updates for both cluster and instance levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"Creating cluster parameter group...\"\n",
    "aws rds create-db-cluster-parameter-group \\\n",
    "    --db-cluster-parameter-group-name aurora-cluster-params \\\n",
    "    --db-parameter-group-family aurora-postgresql16 \\\n",
    "    --description \"Custom cluster parameters for Aurora\"\n",
    "\n",
    "echo \"Creating DB parameter group...\"\n",
    "aws rds create-db-parameter-group \\\n",
    "    --db-parameter-group-name aurora-instance-params \\\n",
    "    --db-parameter-group-family aurora-postgresql16 \\\n",
    "    --description \"Custom instance parameters for Aurora\"\n",
    "\n",
    "# Modify key parameters\n",
    "echo \"Configuring parameters...\"\n",
    "aws rds modify-db-cluster-parameter-group \\\n",
    "    --db-cluster-parameter-group-name aurora-cluster-params \\\n",
    "    --parameters \"ParameterName=rds.force_ssl,ParameterValue=0,ApplyMethod=pending-reboot\" \\\n",
    "                 \"ParameterName=shared_preload_libraries,ParameterValue=pg_stat_statements\\,pg_hint_plan\\,auto_explain,ApplyMethod=pending-reboot\"\n",
    "\n",
    "aws rds modify-db-parameter-group \\\n",
    "    --db-parameter-group-name aurora-instance-params \\\n",
    "    --parameters \"ParameterName=log_rotation_age,ParameterValue=1440,ApplyMethod=pending-reboot\" \\\n",
    "                 \"ParameterName=log_rotation_size,ParameterValue=102400,ApplyMethod=pending-reboot\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25138bee",
   "metadata": {},
   "source": [
    "## Step 4: Create Aurora Cluster\n",
    "\n",
    "Create an Aurora PostgreSQL Serverless v2 cluster with managed secret for enhanced security. The cluster uses cost-optimized settings including auto-pause functionality, capacity scaling (0-4 ACU), and standard storage configuration. AWS automatically creates and manages the master user password in Secrets Manager. You'll see cluster creation progress and a wait period for availability confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Source variables\n",
    "source .env_vars\n",
    "\n",
    "echo \"Using security group: $SG_ID\"\n",
    "\n",
    "echo \"Creating Aurora PostgreSQL cluster with managed secret...\"\n",
    "aws rds create-db-cluster \\\n",
    "    --db-cluster-identifier aurora-demo \\\n",
    "    --engine aurora-postgresql \\\n",
    "    --engine-version 16.8 \\\n",
    "    --master-username masteruser \\\n",
    "    --manage-master-user-password \\\n",
    "    --database-name mylab \\\n",
    "    --db-subnet-group-name $SUBNET_GROUP_NAME \\\n",
    "    --vpc-security-group-ids $SG_ID \\\n",
    "    --db-cluster-parameter-group-name aurora-cluster-params \\\n",
    "    --serverless-v2-scaling-configuration MinCapacity=0,MaxCapacity=4,SecondsUntilAutoPause=600 \\\n",
    "    --backup-retention-period 1 \\\n",
    "    --storage-encrypted \\\n",
    "    --enable-http-endpoint \\\n",
    "    --enable-iam-database-authentication \\\n",
    "    --tags Key=Environment,Value=Development \\\n",
    "    --no-deletion-protection \\\n",
    "    --engine-lifecycle-support open-source-rds-extended-support-disabled\n",
    "\n",
    "echo \"Waiting for cluster to become available (this may take a few minutes)...\"\n",
    "aws rds wait db-cluster-available --db-cluster-identifier aurora-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cluster-status-check",
   "metadata": {},
   "source": [
    "### Verify Cluster Status\n",
    "\n",
    "Check that the Aurora cluster is up and running with all expected configurations before proceeding to the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cluster-status-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"🔍 Verifying Aurora cluster status...\"\n",
    "\n",
    "# Check cluster status and configuration\n",
    "CLUSTER_STATUS=$(aws rds describe-db-clusters --db-cluster-identifier aurora-demo --query 'DBClusters[0].Status' --output text)\n",
    "\n",
    "if [ \"$CLUSTER_STATUS\" = \"available\" ]; then\n",
    "    echo \"✅ Cluster is available and ready\"\n",
    "    \n",
    "    # Display cluster details\n",
    "    aws rds describe-db-clusters --db-cluster-identifier aurora-demo \\\n",
    "        --query 'DBClusters[0].{Status:Status,Engine:Engine,Version:EngineVersion,Endpoint:Endpoint,ReaderEndpoint:ReaderEndpoint,ServerlessV2:ServerlessV2ScalingConfiguration}' \\\n",
    "        --output table\n",
    "    \n",
    "    echo \"✅ Cluster verification complete - ready for next steps\"\n",
    "else\n",
    "    echo \"❌ Cluster status: $CLUSTER_STATUS\"\n",
    "    echo \"Please wait for cluster to become available before proceeding\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2239e7f4",
   "metadata": {},
   "source": [
    "## Step 5: Associate S3 Import Role with Cluster\n",
    "\n",
    "Associate the previously created S3 import IAM role with the Aurora cluster, enabling the aws_s3 extension to import and export data directly from S3 buckets. The role attachment provides the necessary permissions for Aurora to access S3 resources securely. You'll see confirmation of the S3 import capability being enabled for the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Source variables\n",
    "source .aurora_vars\n",
    "source .env_vars\n",
    "\n",
    "echo \"Adding S3 import role to cluster...\"\n",
    "aws rds add-role-to-db-cluster \\\n",
    "    --db-cluster-identifier aurora-demo \\\n",
    "    --role-arn $S3_ROLE_ARN \\\n",
    "    --feature-name s3Import\n",
    "\n",
    "echo \"✅ S3 import capability enabled\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c367a",
   "metadata": {},
   "source": [
    "## Step 6: Create Writer and Reader Instances\n",
    "\n",
    "Create both writer and reader instances for the Aurora cluster using the db.serverless instance class with Performance Insights enabled for monitoring. Both instances use custom parameter groups and include 7-day Performance Insights retention within the free tier. You'll see instance creation progress, availability confirmation, and detailed instance information including status and availability zone for both instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Source variables\n",
    "source .aurora_vars\n",
    "source .env_vars\n",
    "\n",
    "echo \"Creating primary writer instance...\"\n",
    "aws rds create-db-instance \\\n",
    "    --db-instance-identifier aurora-writer \\\n",
    "    --db-cluster-identifier aurora-demo \\\n",
    "    --db-instance-class db.serverless \\\n",
    "    --engine aurora-postgresql \\\n",
    "    --db-parameter-group-name aurora-instance-params \\\n",
    "    --enable-performance-insights \\\n",
    "    --performance-insights-retention-period 7 \\\n",
    "    --monitoring-interval 60 \\\n",
    "    --monitoring-role-arn $MONITORING_ROLE_ARN \\\n",
    "    --tags Key=Role,Value=Writer\n",
    "\n",
    "echo \"Waiting for writer instance to become available (this may take 5-10 minutes)...\"\n",
    "aws rds wait db-instance-available --db-instance-identifier aurora-writer\n",
    "\n",
    "echo \"Creating reader instance...\"\n",
    "aws rds create-db-instance \\\n",
    "    --db-instance-identifier aurora-reader \\\n",
    "    --db-cluster-identifier aurora-demo \\\n",
    "    --db-instance-class db.serverless \\\n",
    "    --engine aurora-postgresql \\\n",
    "    --db-parameter-group-name aurora-instance-params \\\n",
    "    --enable-performance-insights \\\n",
    "    --performance-insights-retention-period 7 \\\n",
    "    --monitoring-interval 60 \\\n",
    "    --monitoring-role-arn $MONITORING_ROLE_ARN \\\n",
    "    --tags Key=Role,Value=Reader\n",
    "\n",
    "echo \"Waiting for reader instance to become available (this may take 5-10 minutes)...\"\n",
    "aws rds wait db-instance-available --db-instance-identifier aurora-reader\n",
    "\n",
    "echo \"✅ Instance details:\"\n",
    "aws rds describe-db-instances \\\n",
    "    --db-instance-identifier aurora-writer \\\n",
    "    --query 'DBInstances[0].{Instance:DBInstanceIdentifier,Status:DBInstanceStatus,Class:DBInstanceClass,AZ:AvailabilityZone}' \\\n",
    "    --output table\n",
    "\n",
    "aws rds describe-db-instances \\\n",
    "    --db-instance-identifier aurora-reader \\\n",
    "    --query 'DBInstances[0].{Instance:DBInstanceIdentifier,Status:DBInstanceStatus,Class:DBInstanceClass,AZ:AvailabilityZone}' \\\n",
    "    --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb3ff8",
   "metadata": {},
   "source": [
    "### Production Recommendation: Add Reader Instance\n",
    "\n",
    "> **💡 Important for Production**: For production environments, we strongly recommend creating at least one reader instance for:\n",
    "> - High availability with automatic failover\n",
    "> - Read scaling for reporting and analytics\n",
    "> - Zero-downtime maintenance operations\n",
    ">\n",
    "> To add a reader instance, use the same command as above but with:\n",
    "> - Different instance identifier (`aurora-reader`)\n",
    "> - Different tag (`Role=Reader`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b0847",
   "metadata": {},
   "source": [
    "## Step 7: Network Diagnostics and Troubleshooting\n",
    "\n",
    "Let's run some network diagnostics to verify our setup and troubleshoot any connectivity issues. The diagnostics provide detailed information about network configuration, routing paths, and access controls for troubleshooting. You'll see formatted tables with security rules, routing information, and network topology details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90001bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Source environment variables\n",
    "source .env_vars\n",
    "\n",
    "echo \"🔍 Running Network Diagnostics...\"\n",
    "\n",
    "echo \"1. Checking Security Group Rules:\"\n",
    "aws ec2 describe-security-group-rules \\\n",
    "    --filters Name=group-id,Values=$SG_ID \\\n",
    "    --query 'SecurityGroupRules[?IpProtocol==`tcp` && FromPort==`5432`]' \\\n",
    "    --output table\n",
    "\n",
    "echo \"2. Checking Network ACLs:\"\n",
    "aws ec2 describe-network-acls \\\n",
    "    --filters Name=vpc-id,Values=$VPC_ID \\\n",
    "    --query 'NetworkAcls[*].{AclId:NetworkAclId,VpcId:VpcId,Entries:Entries[0:5]}' \\\n",
    "    --output table\n",
    "\n",
    "echo \"3. Checking Route Tables:\"\n",
    "aws ec2 describe-route-tables \\\n",
    "    --filters Name=vpc-id,Values=$VPC_ID \\\n",
    "    --query 'RouteTables[*].{RouteTableId:RouteTableId,Routes:Routes[*].{Destination:DestinationCidrBlock,Target:GatewayId||NatGatewayId||VpcPeeringConnectionId||TransitGatewayId||LocalGatewayId||CarrierGatewayId||NetworkInterfaceId||VpcEndpointId}}' \\\n",
    "    --output table\n",
    "\n",
    "echo \"4. Checking Subnet Connectivity:\"\n",
    "aws ec2 describe-subnets \\\n",
    "    --filters Name=vpc-id,Values=$VPC_ID \\\n",
    "    --query 'Subnets[*].{SubnetId:SubnetId,CIDR:CidrBlock,AZ:AvailabilityZone,Public:MapPublicIpOnLaunch}' \\\n",
    "    --output table\n",
    "\n",
    "echo \"✅ Network diagnostics complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25faf42f",
   "metadata": {},
   "source": [
    "Check the Aurora cluster is healthy and available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"🔍 Running Aurora Diagnostics...\"\n",
    "\n",
    "echo \"1. Checking cluster status:\"\n",
    "aws rds describe-db-clusters \\\n",
    "    --db-cluster-identifier aurora-demo \\\n",
    "    --query 'DBClusters[0].{Status:Status,Engine:Engine,Version:EngineVersion}' \\\n",
    "    --output table\n",
    "\n",
    "echo \"2. Checking recent events:\"\n",
    "aws rds describe-events \\\n",
    "    --source-identifier aurora-demo \\\n",
    "    --source-type db-cluster \\\n",
    "    --duration 60 \\\n",
    "    --query 'Events[*].{Time:Date,Message:Message}' \\\n",
    "    --output table\n",
    "\n",
    "echo \"3. Checking Performance Insights enabled:\"\n",
    "aws rds describe-db-instances \\\n",
    "    --db-instance-identifier aurora-writer \\\n",
    "    --query 'DBInstances[0].PerformanceInsightsEnabled'\n",
    "\n",
    "echo \"✅ Aurora diagnostics complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0c713",
   "metadata": {},
   "source": [
    "## Summary and Resources Created\n",
    "\n",
    "Let's review what we've created in this lab. This summary script provides an overview of all AWS resources created during the Aurora cluster setup process. The output includes IAM roles, database resources, security components, and advanced features with their current status. You'll see a complete inventory of created resources and their configurations for reference and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Source variables\n",
    "source .aurora_vars 2>/dev/null || true\n",
    "source .env_vars 2>/dev/null || true\n",
    "\n",
    "echo \"📋 Resources Created Summary\"\n",
    "\n",
    "echo \"1. IAM Roles:\"\n",
    "if [ ! -z \"$S3_ROLE_ARN\" ]; then\n",
    "    echo \"S3 Import Role: $S3_ROLE_ARN\"\n",
    "fi\n",
    "if [ ! -z \"$MONITORING_ROLE_ARN\" ]; then\n",
    "    echo \"Monitoring Role: $MONITORING_ROLE_ARN\"\n",
    "fi\n",
    "\n",
    "echo \"2. Database Resources:\"\n",
    "aws rds describe-db-clusters --db-cluster-identifier aurora-demo --query 'DBClusters[0].{Cluster:DBClusterIdentifier,Status:Status,Engine:Engine,Version:EngineVersion,Endpoint:Endpoint}' --output table\n",
    "aws rds describe-db-instances --query 'DBInstances[?DBClusterIdentifier==`aurora-demo`].{Instance:DBInstanceIdentifier,Status:DBInstanceStatus,Class:DBInstanceClass,Role:ReadReplicaSourceDBInstanceIdentifier||`Writer`}' --output table\n",
    "if [ ! -z \"$SUBNET_GROUP_NAME\" ]; then\n",
    "    aws rds describe-db-subnet-groups --db-subnet-group-name $SUBNET_GROUP_NAME --query 'DBSubnetGroups[0].{Name:DBSubnetGroupName,Status:SubnetGroupStatus}' --output table\n",
    "fi\n",
    "\n",
    "echo \"3. Security Resources:\"\n",
    "# Get managed secret created by Aurora\n",
    "MANAGED_SECRET=$(aws rds describe-db-clusters --db-cluster-identifier aurora-demo --query 'DBClusters[0].MasterUserSecret.SecretArn' --output text 2>/dev/null)\n",
    "if [ \"$MANAGED_SECRET\" != \"None\" ] && [ ! -z \"$MANAGED_SECRET\" ]; then\n",
    "    echo \"Managed Secret (Aurora-created):\"\n",
    "    aws secretsmanager describe-secret --secret-id $MANAGED_SECRET --query '{Name:Name,Arn:ARN,Description:Description}' --output table\n",
    "else\n",
    "    echo \"No managed secret found\"\n",
    "fi\n",
    "if [ ! -z \"$SG_ID\" ]; then\n",
    "    aws ec2 describe-security-groups --group-ids $SG_ID --query 'SecurityGroups[0].{GroupId:GroupId,Name:GroupName,VpcId:VpcId}' --output table\n",
    "fi\n",
    "\n",
    "echo \"✅ Congratulations! You've successfully created a cost-optimized Aurora PostgreSQL cluster with managed secret.\"\n",
    "echo \"   Your database is now ready to use for development and testing purposes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456adafe",
   "metadata": {},
   "source": [
    "## Next Steps 🚀\n",
    "\n",
    "Now that you've successfully created your Aurora PostgreSQL cluster with advanced features, it's time to learn how to connect to it and work with your data:\n",
    "\n",
    "1. **Connect to Your Aurora Database**\n",
    "   - Learn different connection methods in [2.2.1 Basic Connectivity](../2.2_Connecting_to_Your_Aurora_PostgreSQL/2.2.1_Basic_Connectivity.ipynb)\n",
    "   - Understand connection pooling and security best practices\n",
    "\n",
    "2. **Work with Your Data**\n",
    "   - Create tables and load data in [2.2.2 Working with Data](../2.2_Connecting_to_Your_Aurora_PostgreSQL/2.2.2_Working_with_Data.ipynb)\n",
    "   - Learn how to optimize queries and manage your database\n",
    "\n",
    "3. **Implement Advanced Connection Management**\n",
    "   - Set up IAM authentication and RDS Proxy in [2.2.3 Advanced Connection Management](../2.2_Connecting_to_Your_Aurora_PostgreSQL/2.2.3_Advanced_Connection_Management.ipynb)\n",
    "   - Configure secure and efficient database access\n",
    "\n",
    "Let's continue to [Section 2.2: Connecting to Your Aurora PostgreSQL](../2.2_Connecting_to_Your_Aurora_PostgreSQL/README.MD) to learn how to interact with your newly created database!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-section",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee9c6b",
   "metadata": {},
   "source": [
    "> ⚠️ **Important**: The following commands will delete Aurora cluster created in this workshop. You will need an Aurora cluster for [4. Operational Excellence: Best Practices for Aurora](../../4_Operational_Excellence_Best_Practices_for_Aurora/README.md), [5. Scaling Your Aurora Database](../../5_Scaling_for_Success_Growing_with_Aurora/README.md), and [7. Break Free from Everything in One Database Trap: A Journey to Purpose-Built AWS Databases](../../7_Break_Free_from_Everything_in_One_Database_Trap_A_Journey_to_Purpose_Built_AWS_Databases/README.md). Only run these if you want to completely remove the Aurora cluster and associated resources. \n",
    "\n",
    "### Cost Consideration\n",
    "Running these cleanup commands will help you avoid ongoing charges for:\n",
    "- Aurora Serverless v2 compute (ACU hours)\n",
    "- Aurora storage\n",
    "- RDS Proxy\n",
    "- Enhanced Monitoring\n",
    "\n",
    "> 💡 **Note**: To clean up the Aurora cluster launched by the AWS CloudFormation template, then go to the [AWS CloudFormation console](https://console.aws.amazon.com/cloudformation/home/), select the AWS CloudFormation stack, and delete it.\n",
    "\n",
    "Resources must be deleted in the correct order due to dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-resources",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"🗑️ Starting cleanup process...\"\n",
    "\n",
    "# 1. Delete RDS Proxy\n",
    "echo \"Deleting RDS Proxy...\"\n",
    "aws rds delete-db-proxy --db-proxy-name aurora-demo-proxy 2>/dev/null || echo \"RDS Proxy not found or already deleted\"\n",
    "\n",
    "# 2. Delete DB Instances\n",
    "echo \"Deleting DB instances...\"\n",
    "aws rds delete-db-instance --db-instance-identifier aurora-reader --skip-final-snapshot 2>/dev/null || echo \"Reader instance not found\"\n",
    "aws rds delete-db-instance --db-instance-identifier aurora-writer --skip-final-snapshot 2>/dev/null || echo \"Writer instance not found\"\n",
    "\n",
    "# Wait for instances to be deleted\n",
    "echo \"Waiting for instances to be deleted...\"\n",
    "sleep 30\n",
    "\n",
    "# 3. Delete Aurora Cluster\n",
    "echo \"Deleting Aurora cluster...\"\n",
    "aws rds delete-db-cluster --db-cluster-identifier aurora-demo --skip-final-snapshot 2>/dev/null || echo \"Cluster not found\"\n",
    "\n",
    "# 4. Delete DB Subnet Group\n",
    "echo \"Deleting DB subnet group...\"\n",
    "source .env_vars 2>/dev/null || true\n",
    "aws rds delete-db-subnet-group --db-subnet-group-name ${SUBNET_GROUP_NAME:-aurora-subnet-group} 2>/dev/null || echo \"Subnet group not found\"\n",
    "\n",
    "# 5. Delete Parameter Groups\n",
    "echo \"Deleting parameter groups...\"\n",
    "aws rds delete-db-cluster-parameter-group --db-cluster-parameter-group-name aurora-cluster-params 2>/dev/null || echo \"Cluster parameter group not found\"\n",
    "aws rds delete-db-parameter-group --db-parameter-group-name aurora-instance-params 2>/dev/null || echo \"Instance parameter group not found\"\n",
    "\n",
    "# 6. Delete Secret\n",
    "echo \"Deleting secret...\"\n",
    "aws secretsmanager delete-secret --secret-id aurora-demo-credentials --force-delete-without-recovery 2>/dev/null || echo \"Secret not found\"\n",
    "\n",
    "# 7. Delete IAM Roles\n",
    "echo \"Deleting IAM roles...\"\n",
    "aws iam detach-role-policy --role-name aurora-s3-import-role --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess 2>/dev/null\n",
    "aws iam delete-role --role-name aurora-s3-import-role 2>/dev/null || echo \"S3 import role not found\"\n",
    "\n",
    "ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)\n",
    "aws iam detach-role-policy --role-name aurora-proxy-role --policy-arn arn:aws:iam::$ACCOUNT_ID:policy/aurora-secrets-policy 2>/dev/null\n",
    "aws iam delete-role --role-name aurora-proxy-role 2>/dev/null || echo \"Proxy role not found\"\n",
    "aws iam delete-policy --policy-arn arn:aws:iam::$ACCOUNT_ID:policy/aurora-secrets-policy 2>/dev/null || echo \"Secrets policy not found\"\n",
    "\n",
    "aws iam detach-role-policy --role-name aurora-monitoring-role --policy-arn arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole 2>/dev/null\n",
    "aws iam delete-role --role-name aurora-monitoring-role 2>/dev/null || echo \"Monitoring role not found\"\n",
    "\n",
    "echo \"✅ Cleanup completed. All Aurora resources have been deleted.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edd207",
   "metadata": {},
   "source": [
    "This step removes temporary files created during the workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Cleanup temporary files\n",
    "rm -f .env_vars .aurora_vars\n",
    "echo \"✅ Temporary files cleaned up\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbf2f6",
   "metadata": {},
   "source": [
    "## Additional Resources 📚\n",
    "\n",
    "### Aurora Features\n",
    "- [Aurora Best Practices](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.BestPractices.html)\n",
    "- [Performance Insights Documentation](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_PerfInsights.html)\n",
    "- [Serverless v2 Capacity Management](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html)\n",
    "\n",
    "### Security & Authentication\n",
    "- [IAM Database Authentication](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html)\n",
    "- [AWS Secrets Manager Integration](https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html)\n",
    "- [RDS Proxy Documentation](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
