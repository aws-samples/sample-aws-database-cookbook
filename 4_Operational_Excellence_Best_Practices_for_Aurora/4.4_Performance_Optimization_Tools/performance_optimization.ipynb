{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CloudWatch Database Insights Setup and Analysis\n",
    "\n",
    "<div style=\"background-color: #f8f9fa; border: 1px solid #e9ecef; border-radius: 8px; padding: 10px; margin: 10px;\">\n",
    "<strong>ðŸ“‹ Workshop Contents</strong>\n",
    "<ul style=\"line-height: 1.2;\">\n",
    "<li><a href=\"#Prerequisites\">Prerequisites</a></li>\n",
    "<li><a href=\"#Setting-up-the-environment-and-required-libraries\">Setting up the environment and required libraries</a></li>\n",
    "<li><a href=\"#1-Setting-up-Database-Insights\">1. Setting up Database Insights</a></li>\n",
    "<li><a href=\"#2-Interpreting-Performance-Recommendations\">2. Interpreting Performance Recommendations</a></li>\n",
    "<li><a href=\"#3-Implementing-Optimizations\">3. Implementing Optimizations</a></li>\n",
    "<li><a href=\"#Usage-Example\">Usage Example</a></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting this workshop, ensure you have:\n",
    "\n",
    "- âœ… **Jupyter Notebook**: You can launch a [free tier Amazon SageMaker Jupyter Notebook](../../1_Getting_Started_with_AWS/1.4_Setting_up_Your_Cookbook_Environment/README.MD)\n",
    "- âœ… **Aurora PostgreSQL Cluster**: An active Aurora PostgreSQL cluster running in your AWS account\n",
    "  - If you don't have one, follow the setup guide: [Your First Database on AWS](../../2_Your_First_Database_on_AWS/README.MD)\n",
    "- âœ… **AWS CLI configured** with appropriate permissions for RDS and Performance Insights\n",
    "- âœ… **Python environment** with boto3 installed\n",
    "- âœ… **IAM permissions** for:\n",
    "  - Performance Insights enablement and access\n",
    "  - RDS instance modifications\n",
    "  - CloudWatch metrics access\n",
    "\n",
    "> ðŸ’¡ **Note**: Performance Insights provides 7 days of retention for free. Extended retention requires additional charges.\n",
    "\n",
    "## Setting up the environment and required libraries\n",
    "\n",
    "This step initializes the required Python libraries and AWS clients for Performance Insights analysis including boto3 for AWS SDK operations, json for data handling, and datetime for time-based metrics collection. You'll see the initialization of RDS, CloudWatch, and Performance Insights clients for comprehensive database monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc28804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize AWS clients\n",
    "rds = boto3.client('rds')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "pi = boto3.client('pi')  # Performance Insights client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up Database Insights\n",
    "\n",
    "This function enables Performance Insights for Aurora instances, providing detailed database performance monitoring with 7-day retention for the free tier. Performance Insights offers deep visibility into database load, wait events, and SQL statement performance with minimal overhead. You'll see the instance modification response confirming Performance Insights activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"Setting Cluster Identifier parameter\"\n",
    "export cluster_identifier=<cluster-identifier>\n",
    "\n",
    "echo \"Configuring Performance Insights\"\n",
    "aws rds modify-db-cluster \\\n",
    "    --db-cluster-identifier $cluster_identifier \\\n",
    "    --database-insights-mode advanced \\\n",
    "    --enable-performance-insights \\\n",
    "    --performance-insights-retention-period 465 \\\n",
    "    --apply-immediately\n",
    "\n",
    "echo \"âœ… Performance Insights configured successfully\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interpreting Performance Recommendations\n",
    "\n",
    "These functions retrieve and analyze Performance Insights metrics to identify performance bottlenecks and generate actionable recommendations. The analysis focuses on database load patterns and wait events to pinpoint specific areas for optimization. You'll see performance metrics data and automated recommendations based on identified performance patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a764a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(resource_id, start_time, end_time):\n",
    "    \"\"\"Retrieve performance metrics from Performance Insights\"\"\"\n",
    "    try:\n",
    "        response = pi.get_resource_metrics(\n",
    "            ServiceType='RDS',\n",
    "            Identifier=resource_id,\n",
    "            StartTime=start_time,\n",
    "            EndTime=end_time,\n",
    "            MetricQueries=[\n",
    "                {\n",
    "                    'Metric': 'db.load.avg',\n",
    "                    'GroupBy': {'Group': 'db.wait_event'}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving performance metrics: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_performance_data(metrics_response):\n",
    "    \"\"\"Analyze performance data and provide recommendations\"\"\"\n",
    "    try:\n",
    "        recommendations = []\n",
    "        if metrics_response and 'MetricList' in metrics_response:\n",
    "            for metric in metrics_response['MetricList']:\n",
    "                if metric['Value'] > 5:  # threshold for high load\n",
    "                    recommendations.append({\n",
    "                        'event': metric['GroupBy']['Value'],\n",
    "                        'load': metric['Value'],\n",
    "                        'suggestion': get_optimization_suggestion(metric['GroupBy']['Value'])\n",
    "                    })\n",
    "        return recommendations\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing performance data: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing Optimizations\n",
    "\n",
    "These functions provide optimization suggestions based on wait event analysis and implement recommended changes including instance scaling and parameter adjustments. The optimization engine maps specific wait events to targeted solutions for improved database performance. You'll see optimization suggestions and implementation responses for applied changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimization_suggestion(wait_event):\n",
    "    \"\"\"Get optimization suggestions based on wait events\"\"\"\n",
    "    suggestions = {\n",
    "        'CPU': 'Consider scaling up instance class or optimizing queries',\n",
    "        'IO:XactSync': 'Optimize transaction commit patterns',\n",
    "        'IO:BufFileRead': 'Increase work_mem to reduce disk I/O',\n",
    "        'LWLock': 'Review and optimize concurrent transactions',\n",
    "        'Lock': 'Check for lock contentions in transactions'\n",
    "    }\n",
    "    return suggestions.get(wait_event, 'Monitor and analyze specific wait event')\n",
    "\n",
    "def apply_optimization(instance_identifier, optimization_type, params):\n",
    "    \"\"\"Apply suggested optimizations to the database\"\"\"\n",
    "    try:\n",
    "        if optimization_type == 'instance_scaling':\n",
    "            response = rds.modify_db_instance(\n",
    "                DBInstanceIdentifier=instance_identifier,\n",
    "                DBInstanceClass=params['new_instance_class'],\n",
    "                ApplyImmediately=True\n",
    "            )\n",
    "        elif optimization_type == 'parameter_update':\n",
    "            response = rds.modify_db_parameter_group(\n",
    "                DBParameterGroupName=params['parameter_group'],\n",
    "                Parameters=params['parameters']\n",
    "            )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying optimization: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "This comprehensive example demonstrates implementing a complete performance optimization workflow including Performance Insights setup, metrics analysis, recommendation generation, and performance monitoring. The script provides end-to-end performance tuning with automated recommendations and improvement tracking. You'll see performance analysis results, optimization recommendations, and measurable performance improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables\n",
    "INSTANCE_IDENTIFIER = 'cluster-identifier'\n",
    "RESOURCE_ID = 'resource-identifier'\n",
    "START_TIME = datetime.utcnow() - timedelta(hours=1)\n",
    "END_TIME = datetime.utcnow()\n",
    "\n",
    "# 1. Enable Performance Insights\n",
    "#insights_config = enable_performance_insights(INSTANCE_IDENTIFIER)\n",
    "print(\"Enabled Performance Insights\")\n",
    "\n",
    "# 2. Get and analyze performance metrics\n",
    "metrics = get_performance_metrics(RESOURCE_ID, START_TIME, END_TIME)\n",
    "recommendations = analyze_performance_data(metrics)\n",
    "print(\"Retrieved performance recommendations\")\n",
    "\n",
    "# 3. Apply optimizations based on recommendations\n",
    "for rec in recommendations:\n",
    "    print(f\"Recommendation for {rec['event']}: {rec['suggestion']}\")\n",
    "\n",
    "# Monitor optimization results\n",
    "def monitor_performance_changes(instance_identifier, start_time, end_time):\n",
    "    try:\n",
    "        # Get performance metrics before and after optimization\n",
    "        metrics = get_performance_metrics(instance_identifier, start_time, end_time)\n",
    "        # Calculate improvement\n",
    "        before_load = sum([m['Value'] for m in metrics['MetricList'][:len(metrics['MetricList'])//2]])\n",
    "        after_load = sum([m['Value'] for m in metrics['MetricList'][len(metrics['MetricList'])//2:]])\n",
    "        improvement = ((before_load - after_load) / before_load) * 100 if before_load > 0 else 0\n",
    "        return {\n",
    "            'before_load': before_load,\n",
    "            'after_load': after_load,\n",
    "            'improvement_percentage': improvement\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error monitoring performance changes: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Monitor the results\n",
    "monitoring_results = monitor_performance_changes(\n",
    "    INSTANCE_IDENTIFIER,\n",
    "    START_TIME,\n",
    "    END_TIME\n",
    ")\n",
    "\n",
    "if monitoring_results:\n",
    "    print(f\"Performance improvement: {monitoring_results['improvement_percentage']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022281e",
   "metadata": {},
   "source": [
    "## Next Steps ðŸš€\n",
    "\n",
    "Now that you've optimized your Aurora database performance, continue building operational excellence with these next steps:\n",
    "\n",
    "1. **Set Up Development and Testing Environments**\n",
    "   - Implement Aurora cloning for testing in [4.5 Aurora Cloning for Testing and Development](../4.5_Aurora_Cloning_for_Testing_and_Development/aurora_cloning_testing_devlop.ipynb)\n",
    "   - Create isolated environments for safe testing and development\n",
    "\n",
    "2. **Scale Your Aurora Infrastructure**\n",
    "   - Learn advanced scaling strategies in [Section 5: Scaling for Success - Growing with Aurora](../../5_Scaling_for_Success_Growing_with_Aurora/README.md)\n",
    "   - Implement vertical and horizontal scaling techniques\n",
    "\n",
    "3. **Implement Advanced Features**\n",
    "   - Explore Aurora Global Database for multi-region deployments\n",
    "   - Set up Aurora Serverless v2 for automatic scaling\n",
    "\n",
    "Continue to [4.5 Set Up Development and Testing Environments](../4.5_Aurora_Cloning_for_Testing_and_Development/aurora_cloning_testing_devlop.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources ðŸ“š\n",
    "\n",
    "### Performance Insights\n",
    "- [Performance Insights User Guide](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_PerfInsights.html)\n",
    "- [Performance Insights API Reference](https://docs.aws.amazon.com/performance-insights/latest/APIReference/)\n",
    "- [Performance Insights Best Practices](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_PerfInsights.BestPractices.html)\n",
    "\n",
    "### Aurora Performance Tuning\n",
    "- [Aurora Performance Best Practices](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.BestPractices.html)\n",
    "- [Aurora MySQL Performance Tuning](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.BestPractices.html)\n",
    "- [Aurora PostgreSQL Performance Tuning](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.BestPractices.html)\n",
    "\n",
    "### Monitoring & Analysis\n",
    "- [CloudWatch Database Insights](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Insights-for-RDS.html)\n",
    "- [Aurora Monitoring Guide](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/MonitoringAurora.html)\n",
    "- [Wait Event Analysis](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_PerfInsights.UsingDashboard.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
